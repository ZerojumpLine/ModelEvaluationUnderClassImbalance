{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, T = 1):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x / T) / np.sum(np.exp(x / T), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class-Specific Temperature-Scaling (CS TS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature-Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare:\n",
    "# -> preacts. N x C\n",
    "# -> labels. N\n",
    "kcls = 10\n",
    "cifar_resultsdir = './data/cifar10results/'\n",
    "cnn_pred = pd.read_csv(cifar_resultsdir + 'predictions_val.csv')\n",
    "targets_all = np.array(cnn_pred[['target_0', 'target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9']])\n",
    "logit_all = np.array(cnn_pred[['logit_0', 'logit_1', 'logit_2', 'logit_3', 'logit_4', 'logit_5', 'logit_6', 'logit_7', 'logit_8', 'logit_9']])\n",
    "preds_all_argmax = np.argmax(logit_all, axis = 1)\n",
    "preacts = logit_all\n",
    "labels = np.argmax(targets_all, axis = 1)\n",
    "def eval_func(x):\n",
    "   \n",
    "    ts_logits = preacts/x\n",
    "    exp_ts_logits = np.exp(ts_logits)\n",
    "    sum_exp = np.sum(exp_ts_logits, axis=1, keepdims=True)\n",
    "    AC = np.mean(np.max(exp_ts_logits/sum_exp, axis=1))\n",
    "    preds = np.argmax(preacts, axis = 1)\n",
    "    acc = np.sum(labels == preds) / len(labels)\n",
    "    MC = np.abs(AC-acc)\n",
    "\n",
    "    return MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_result = scipy.optimize.minimize(\n",
    "                          fun=eval_func,\n",
    "                          x0=np.array([1.0]),\n",
    "                          method='Nelder-Mead',\n",
    "                          tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0181127548217805\n"
     ]
    }
   ],
   "source": [
    "LearedTemp = optimization_result.x[0]\n",
    "print(LearedTemp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-Specific Temperature-Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nl/7_2jcxd12wb5z06jvsj1v4240000gn/T/ipykernel_38152/969388628.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return np.exp(x / T) / np.sum(np.exp(x / T), axis=0)\n",
      "/var/folders/nl/7_2jcxd12wb5z06jvsj1v4240000gn/T/ipykernel_38152/969388628.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(x / T) / np.sum(np.exp(x / T), axis=0)\n"
     ]
    }
   ],
   "source": [
    "LearnedTempsCS = []\n",
    "for kcls in range(10):\n",
    "    label = kcls\n",
    "    # -> preacts. N x C\n",
    "    # -> labels. N\n",
    "    def eval_func(x):\n",
    "\n",
    "        targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "        pred_class = np.argmax(logit_all, axis = 1)[targets_y1]\n",
    "        target_class = np.argmax(targets_all, axis = 1)[targets_y1]\n",
    "\n",
    "        acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "        prob_Topt = softmax(logit_all.transpose(), T = x).transpose()[targets_y1]\n",
    "        AC = np.mean(np.max(prob_Topt, axis = 1))\n",
    "\n",
    "        MC = np.abs(AC-acc)\n",
    "\n",
    "        return MC\n",
    "    optimization_result = scipy.optimize.minimize(\n",
    "                          fun=eval_func,\n",
    "                          x0=np.array([1.0]),\n",
    "                          method='Nelder-Mead',\n",
    "                          bounds=[(0,None)],\n",
    "                          tol=1e-07)\n",
    "    LearnedTempsCS.append(optimization_result.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.052276134490974, 5.051852416992195, 3.1226871490478563, 3.831060886383063, 2.1635234832763697, 1.9345229148864767, 1.0908403396606448, 0.5756251335144038, 0.3874131202697748, 0.18110818862914965]\n"
     ]
    }
   ],
   "source": [
    "print(LearnedTempsCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# bring a test condition here.\n",
    "acc_results = []\n",
    "AC_results = []\n",
    "TS_results = []\n",
    "CSTS_results = []\n",
    "cifar_resultsdir = './data/cifar10results/'\n",
    "corruptions = ['motion_blur']\n",
    "cifar_resultsdir = './data/cifar10results/'\n",
    "cnn_pred = pd.read_csv(cifar_resultsdir + 'predictions_val.csv')\n",
    "for cname in tqdm(corruptions):\n",
    "    csvfilename = cifar_resultsdir + 'predictions_val_' + cname + '.csv'\n",
    "    cnn_pred_all = pd.read_csv(csvfilename)\n",
    "    for severity in range(5):\n",
    "        cnn_pred = cnn_pred_all.iloc[severity * 10000:(severity + 1) * 10000, :]\n",
    "        \n",
    "        kcls = 10\n",
    "        targets_all = np.array(cnn_pred[['target_0', 'target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9']])\n",
    "        logit_all = np.array(cnn_pred[['logit_0', 'logit_1', 'logit_2', 'logit_3', 'logit_4', 'logit_5', 'logit_6', 'logit_7', 'logit_8', 'logit_9']])\n",
    "        preds_all_argmax = np.argmax(logit_all, axis = 1)\n",
    "        # acc\n",
    "        target_class = np.argmax(targets_all, axis = 1)\n",
    "        pred_class = np.argmax(logit_all, axis = 1)\n",
    "        acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "        prob = softmax(logit_all.transpose(), T = 1).transpose()\n",
    "        probmax = np.max(prob, axis = 1)\n",
    "        prob_Topt = softmax(logit_all.transpose(), T = LearedTemp).transpose()\n",
    "        prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "        acc_results.append(acc)\n",
    "        AC_results.append(np.mean(probmax))\n",
    "        TS_results.append(np.mean(prob_Toptmax))\n",
    "        targets_all = []\n",
    "        preds_class_all = []\n",
    "        for label in range(kcls):\n",
    "            preds_all = softmax(logit_all.transpose(), T = LearnedTempsCS[label]).transpose()\n",
    "            preds_all_max = np.max(preds_all, axis = 1)\n",
    "            targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "            preds_class = preds_all_max[targets_y1]\n",
    "\n",
    "            preds_class_all = np.concatenate((preds_class_all, preds_class), axis=0)\n",
    "        CSTS_results.append(np.mean(preds_class_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC_results:\n",
      "0.40090712038075144\n",
      "TS_results:\n",
      "0.13801236936781258\n",
      "CSTS_results:\n",
      "0.07333104279565443\n"
     ]
    }
   ],
   "source": [
    "print('AC_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(AC_results))))\n",
    "print('TS_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(TS_results))))\n",
    "print('CSTS_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(CSTS_results))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-Specific Difference of Confidences (CS DoC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference of Confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcls = 10\n",
    "cifar_resultsdir = './data/cifar10results/'\n",
    "cnn_pred = pd.read_csv(cifar_resultsdir + 'predictions_val.csv')\n",
    "targets_all = np.array(cnn_pred[['target_0', 'target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9']])\n",
    "logit_all = np.array(cnn_pred[['logit_0', 'logit_1', 'logit_2', 'logit_3', 'logit_4', 'logit_5', 'logit_6', 'logit_7', 'logit_8', 'logit_9']])\n",
    "# acc\n",
    "target_class = np.argmax(targets_all, axis = 1)\n",
    "pred_class = np.argmax(logit_all, axis = 1)\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "prob = softmax(logit_all.transpose(), T = 1).transpose()\n",
    "probmax = np.max(prob, axis = 1)\n",
    "AC = np.mean(probmax)\n",
    "DoC = AC-acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2052864551906859\n"
     ]
    }
   ],
   "source": [
    "print(DoC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-Specific Difference of Confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_all = []\n",
    "preds_class_all = []\n",
    "CS_DoC = []\n",
    "preds_all = np.array(cnn_pred[['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9']])\n",
    "preds_all_argmax = np.argmax(preds_all, axis = 1)\n",
    "preds_all_max = np.max(preds_all, axis = 1)\n",
    "class_all = np.array(cnn_pred[['target_0', 'target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9']])\n",
    "class_all_argmax = np.argmax(class_all, axis = 1)\n",
    "for label in range(kcls):\n",
    "    targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "    preds_class = preds_all_max[targets_y1]\n",
    "    \n",
    "    preds_class_all = np.concatenate((preds_class_all, preds_class), axis=0)\n",
    "    \n",
    "    preds_realclass = class_all_argmax[targets_y1]\n",
    "    targets_all = np.concatenate((targets_all, np.ones(len(preds_class)) * label), axis=0)\n",
    "    CS_DoC.append(np.mean(preds_class)-np.sum(preds_realclass == label) / len(targets_y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40958592283590023, 0.2789425803337875, 0.22524099353658522, 0.32926383236198475, 0.11855897708978325, 0.10672835044499385, 0.008215537769131087, -0.041816004999999934, -0.060100967121211935, -0.0783179302022472]\n"
     ]
    }
   ],
   "source": [
    "print(CS_DoC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# bring a test condition here.\n",
    "acc_results = []\n",
    "AC_results = []\n",
    "DoC_results = []\n",
    "CSDoC_results = []\n",
    "cifar_resultsdir = './data/cifar10results/'\n",
    "corruptions = ['motion_blur']\n",
    "\n",
    "for cname in tqdm(corruptions):\n",
    "    csvfilename = cifar_resultsdir + 'predictions_val_' + cname + '.csv'\n",
    "    cnn_pred_all = pd.read_csv(csvfilename)\n",
    "    for severity in range(5):\n",
    "        cnn_pred = cnn_pred_all.iloc[severity * 10000:(severity + 1) * 10000, :]\n",
    "        \n",
    "        kcls = 10\n",
    "        targets_all = np.array(cnn_pred[['target_0', 'target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9']])\n",
    "        logit_all = np.array(cnn_pred[['logit_0', 'logit_1', 'logit_2', 'logit_3', 'logit_4', 'logit_5', 'logit_6', 'logit_7', 'logit_8', 'logit_9']])\n",
    "        preds_all_argmax = np.argmax(logit_all, axis = 1)\n",
    "        # acc\n",
    "        target_class = np.argmax(targets_all, axis = 1)\n",
    "        pred_class = np.argmax(logit_all, axis = 1)\n",
    "        acc_t = np.sum(pred_class == target_class) / len(target_class)\n",
    "        prob = softmax(logit_all.transpose(), T = 1).transpose()\n",
    "        probmax = np.max(prob, axis = 1)\n",
    "        acc_results.append(acc_t)\n",
    "        AC_results.append(np.mean(probmax))\n",
    "        DoC_results.append(np.mean(probmax)-DoC)\n",
    "        targets_all = []\n",
    "        preds_class_all = []\n",
    "        for label in range(kcls):\n",
    "            preds_all = softmax(logit_all.transpose(), T = 1).transpose()\n",
    "            preds_all_max = np.max(preds_all, axis = 1)\n",
    "            targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "            preds_class = preds_all_max[targets_y1]\n",
    "\n",
    "            preds_class_all = np.concatenate((preds_class_all, preds_class - CS_DoC[label]), axis=0)\n",
    "        CSDoC_results.append(np.mean(preds_class_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC_results:\n",
      "0.40090712038075144\n",
      "DoC_results:\n",
      "0.19562066519006555\n",
      "CSDoC_results:\n",
      "0.12715689026860238\n"
     ]
    }
   ],
   "source": [
    "print('AC_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(AC_results))))\n",
    "print('DoC_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(DoC_results))))\n",
    "print('CSDoC_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(CSDoC_results))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-Specific Average Thresholded Confidence (CS ATC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Thresholded Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare:\n",
    "# -> preacts. N x C\n",
    "# -> labels. N\n",
    "kcls = 10\n",
    "cifar_resultsdir = './data/cifar10results/'\n",
    "cnn_pred = pd.read_csv(cifar_resultsdir + 'predictions_val.csv')\n",
    "targets_all = np.array(cnn_pred[['target_0', 'target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9']])\n",
    "logit_all = np.array(cnn_pred[['logit_0', 'logit_1', 'logit_2', 'logit_3', 'logit_4', 'logit_5', 'logit_6', 'logit_7', 'logit_8', 'logit_9']])\n",
    "preds_all_argmax = np.argmax(logit_all, axis = 1)\n",
    "preacts = logit_all\n",
    "labels = np.argmax(targets_all, axis = 1)\n",
    "def eval_func(x):\n",
    "    \n",
    "    prob = softmax(logit_all.transpose(), T = 1).transpose()\n",
    "    probmax = np.max(prob, axis = 1)\n",
    "    acc_appr = np.sum(probmax > x) / len(labels)\n",
    "    \n",
    "    preds = np.argmax(preacts, axis = 1)\n",
    "    acc = np.sum(labels == preds) / len(labels)\n",
    "    \n",
    "    MC = np.abs(acc_appr-acc)\n",
    "\n",
    "    return MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_result = scipy.optimize.minimize(\n",
    "                          fun=eval_func,\n",
    "                          x0=np.array([1.0]),\n",
    "                          method='Nelder-Mead',\n",
    "                          tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9285644531249999\n"
     ]
    }
   ],
   "source": [
    "LearedThreshold = optimization_result.x[0]\n",
    "print(LearedThreshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-Specific Average Thresholded Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearnedThresholdCS = []\n",
    "for kcls in range(10):\n",
    "    label = kcls\n",
    "    # -> preacts. N x C\n",
    "    # -> labels. N\n",
    "    def eval_func(x):\n",
    "\n",
    "        targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "        target_class = np.argmax(targets_all, axis = 1)[targets_y1]\n",
    "        pred_class = np.argmax(logit_all, axis = 1)[targets_y1]\n",
    "        acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "        prob = softmax(logit_all.transpose(), T = 1).transpose()[targets_y1]\n",
    "        probmax = np.max(prob, axis = 1)\n",
    "\n",
    "        acc_appr = np.sum(probmax > x) / len(target_class)\n",
    "\n",
    "        MC = np.abs(acc_appr-acc)\n",
    "\n",
    "        return MC\n",
    "    optimization_result = scipy.optimize.minimize(\n",
    "                          fun=eval_func,\n",
    "                          x0=np.array([1.0]),\n",
    "                          method='Nelder-Mead',\n",
    "                          tol=1e-07)\n",
    "    LearnedThresholdCS.append(optimization_result.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9974121093750001, 0.9984619140625002, 0.9273437499999999, 0.9602539062499998, 0.840234375, 0.7640624999999998, 0.6718749999999997, 0.5499999999999996, 0.5468749999999996, 0.39999999999999947]\n"
     ]
    }
   ],
   "source": [
    "print(LearnedThresholdCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# bring a test condition here.\n",
    "acc_results = []\n",
    "AC_results = []\n",
    "ATC_results = []\n",
    "CSATC_results = []\n",
    "cifar_resultsdir = './data/cifar10results/'\n",
    "corruptions = ['motion_blur']\n",
    "\n",
    "for cname in tqdm(corruptions):\n",
    "    csvfilename = cifar_resultsdir + 'predictions_val_' + cname + '.csv'\n",
    "    cnn_pred_all = pd.read_csv(csvfilename)\n",
    "    for severity in range(5):\n",
    "        cnn_pred = cnn_pred_all.iloc[severity * 10000:(severity + 1) * 10000, :]\n",
    "        \n",
    "        kcls = 10\n",
    "        targets_all = np.array(cnn_pred[['target_0', 'target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9']])\n",
    "        logit_all = np.array(cnn_pred[['logit_0', 'logit_1', 'logit_2', 'logit_3', 'logit_4', 'logit_5', 'logit_6', 'logit_7', 'logit_8', 'logit_9']])\n",
    "        preds_all_argmax = np.argmax(logit_all, axis = 1)\n",
    "        # acc\n",
    "        target_class = np.argmax(targets_all, axis = 1)\n",
    "        pred_class = np.argmax(logit_all, axis = 1)\n",
    "        acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "        prob = softmax(logit_all.transpose(), T = 1).transpose()\n",
    "        probmax = np.max(prob, axis = 1)\n",
    "        acc_results.append(acc)\n",
    "        AC_results.append(np.mean(probmax))\n",
    "        ATC_results.append(np.sum(probmax > LearedThreshold) / len(target_class))\n",
    "        hit_cnt = 0\n",
    "        for label in range(kcls):\n",
    "            preds_all = softmax(logit_all.transpose(), T = 1).transpose()\n",
    "            preds_all_max = np.max(preds_all, axis = 1)\n",
    "            targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "            preds_class = preds_all_max[targets_y1]\n",
    "\n",
    "        #     print(np.sum(preds_class > learnTs[label]) / len(targets_y1))\n",
    "            hit_cnt += np.sum(preds_class > LearnedThresholdCS[label])\n",
    "        CSATC_results.append(hit_cnt / len(target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC_results:\n",
      "0.40090712038075144\n",
      "ATC_results:\n",
      "0.12510000000000004\n",
      "CSATC_results:\n",
      "0.04414\n"
     ]
    }
   ],
   "source": [
    "print('AC_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(AC_results))))\n",
    "print('ATC_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(ATC_results))))\n",
    "print('CSATC_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(CSATC_results))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-Specific Temperature-Scaling Average Thresholded Confidence (CS TS-ATC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature-Scaling Average Thresholded Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare:\n",
    "# -> preacts. N x C\n",
    "# -> labels. N\n",
    "kcls = 10\n",
    "cifar_resultsdir = './data/cifar10results/'\n",
    "cnn_pred = pd.read_csv(cifar_resultsdir + 'predictions_val.csv')\n",
    "targets_all = np.array(cnn_pred[['target_0', 'target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9']])\n",
    "logit_all = np.array(cnn_pred[['logit_0', 'logit_1', 'logit_2', 'logit_3', 'logit_4', 'logit_5', 'logit_6', 'logit_7', 'logit_8', 'logit_9']])\n",
    "preds_all_argmax = np.argmax(logit_all, axis = 1)\n",
    "preacts = logit_all\n",
    "labels = np.argmax(targets_all, axis = 1)\n",
    "def eval_func(x):\n",
    "    \n",
    "    prob = softmax(logit_all.transpose(), T = LearedTemp).transpose()\n",
    "    probmax = np.max(prob, axis = 1)\n",
    "    acc_appr = np.sum(probmax > x) / len(labels)\n",
    "    \n",
    "    preds = np.argmax(preacts, axis = 1)\n",
    "    acc = np.sum(labels == preds) / len(labels)\n",
    "    \n",
    "    MC = np.abs(acc_appr-acc)\n",
    "\n",
    "    return MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_result = scipy.optimize.minimize(\n",
    "                          fun=eval_func,\n",
    "                          x0=np.array([1.0]),\n",
    "                          method='Nelder-Mead',\n",
    "                          tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5443847656249996\n"
     ]
    }
   ],
   "source": [
    "LearedThreshold = optimization_result.x[0]\n",
    "print(LearedThreshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-Specific Temperature-Scaling Average Thresholded Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearnedThresholdCS = []\n",
    "for kcls in range(10):\n",
    "    label = kcls\n",
    "    # -> preacts. N x C\n",
    "    # -> labels. N\n",
    "    def eval_func(x):\n",
    "\n",
    "        targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "        target_class = np.argmax(targets_all, axis = 1)[targets_y1]\n",
    "        pred_class = np.argmax(logit_all, axis = 1)[targets_y1]\n",
    "        acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "        prob = softmax(logit_all.transpose(), T = LearnedTempsCS[label]).transpose()[targets_y1]\n",
    "        probmax = np.max(prob, axis = 1)\n",
    "\n",
    "        acc_appr = np.sum(probmax > x) / len(target_class)\n",
    "\n",
    "        MC = np.abs(acc_appr-acc)\n",
    "\n",
    "        return MC\n",
    "    optimization_result = scipy.optimize.minimize(\n",
    "                          fun=eval_func,\n",
    "                          x0=np.array([1.0]),\n",
    "                          method='Nelder-Mead',\n",
    "                          tol=1e-07)\n",
    "    LearnedThresholdCS.append(optimization_result.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48828124999999956, 0.5343749999999996, 0.5203124999999996, 0.48749999999999954, 0.5683593749999997, 0.5812499999999996, 0.6437499999999997, 0.6624999999999996, 0.6437499999999997, 0.6499999999999997]\n"
     ]
    }
   ],
   "source": [
    "print(LearnedThresholdCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# bring a test condition here.\n",
    "acc_results = []\n",
    "AC_results = []\n",
    "ATC_results = []\n",
    "CSATC_results = []\n",
    "cifar_resultsdir = './data/cifar10results/'\n",
    "corruptions = ['motion_blur']\n",
    "\n",
    "for cname in tqdm(corruptions):\n",
    "    csvfilename = cifar_resultsdir + 'predictions_val_' + cname + '.csv'\n",
    "    cnn_pred_all = pd.read_csv(csvfilename)\n",
    "    for severity in range(5):\n",
    "        cnn_pred = cnn_pred_all.iloc[severity * 10000:(severity + 1) * 10000, :]\n",
    "        \n",
    "        kcls = 10\n",
    "        targets_all = np.array(cnn_pred[['target_0', 'target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9']])\n",
    "        logit_all = np.array(cnn_pred[['logit_0', 'logit_1', 'logit_2', 'logit_3', 'logit_4', 'logit_5', 'logit_6', 'logit_7', 'logit_8', 'logit_9']])\n",
    "        preds_all_argmax = np.argmax(logit_all, axis = 1)\n",
    "        # acc\n",
    "        target_class = np.argmax(targets_all, axis = 1)\n",
    "        pred_class = np.argmax(logit_all, axis = 1)\n",
    "        acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "        prob = softmax(logit_all.transpose(), T = LearedTemp).transpose()\n",
    "        probmax = np.max(prob, axis = 1)\n",
    "        acc_results.append(acc)\n",
    "        AC_results.append(np.mean(probmax))\n",
    "        ATC_results.append(np.sum(probmax > LearedThreshold) / len(target_class))\n",
    "        hit_cnt = 0\n",
    "        for label in range(kcls):\n",
    "            preds_all = softmax(logit_all.transpose(), T = LearnedTempsCS[label]).transpose()\n",
    "            preds_all_max = np.max(preds_all, axis = 1)\n",
    "            targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "            preds_class = preds_all_max[targets_y1]\n",
    "\n",
    "        #     print(np.sum(preds_class > learnTs[label]) / len(targets_y1))\n",
    "            hit_cnt += np.sum(preds_class > LearnedThresholdCS[label])\n",
    "        CSATC_results.append(hit_cnt / len(target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC_results:\n",
      "0.13801236936781258\n",
      "TS_ATC_results:\n",
      "0.09695999999999999\n",
      "CSTS_ATC_results:\n",
      "0.022860000000000002\n"
     ]
    }
   ],
   "source": [
    "print('AC_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(AC_results))))\n",
    "print('TS_ATC_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(ATC_results))))\n",
    "print('CSTS_ATC_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(CSATC_results))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modeleval",
   "language": "python",
   "name": "modeleval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
