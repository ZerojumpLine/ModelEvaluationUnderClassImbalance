{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, T, b=0):\n",
    "    x = x / T + b\n",
    "    f = np.exp(x - np.max(x, axis = 0))  # shift values\n",
    "    return f / f.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_resultsdir = '/vol/biomedic3/zl9518/ModelEvaluation/LDAM-DRW/cifar10results/'\n",
    "cnn_pred = pd.read_csv(cifar_resultsdir + 'predictions_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7054\n",
      "0.9106864551906859\n",
      "0.7072816176222978\n"
     ]
    }
   ],
   "source": [
    "kcls = 10\n",
    "targets_all = np.array(cnn_pred[['target_0', 'target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9']])\n",
    "logit_all = np.array(cnn_pred[['logit_0', 'logit_1', 'logit_2', 'logit_3', 'logit_4', 'logit_5', 'logit_6', 'logit_7', 'logit_8', 'logit_9']])\n",
    "preds_all_argmax = np.argmax(logit_all, axis = 1)\n",
    "# acc\n",
    "target_class = np.argmax(targets_all, axis = 1)\n",
    "pred_class = np.argmax(logit_all, axis = 1)\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "prob = softmax(logit_all.transpose(), T = 1).transpose()\n",
    "probmax = np.max(prob, axis = 1)\n",
    "prob_Topt = softmax(logit_all.transpose(), T = 3.0).transpose()\n",
    "prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "print(acc)\n",
    "print(np.mean(probmax))\n",
    "print(np.mean(prob_Toptmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preacts = logit_all\n",
    "labels = target_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare:\n",
    "# -> preacts. N x C\n",
    "# -> labels. N\n",
    "def eval_func(x):\n",
    "    ws = np.array(x[:int(len(x)/2)])\n",
    "    bs = np.array(x[int(len(x)/2):]) \n",
    "\n",
    "    vs_logits = preacts/ws[None,:] + bs[None,:]\n",
    "    exp_vs_logits = np.exp(vs_logits)\n",
    "    sum_exp = np.sum(exp_vs_logits, axis=1, keepdims=True)\n",
    "    AC = np.mean(np.max(exp_vs_logits/sum_exp, axis=1))\n",
    "    preds = np.argmax(preacts, axis = 1)\n",
    "    acc = np.sum(labels == preds) / len(labels)\n",
    "    MC = np.abs(AC-acc)\n",
    "\n",
    "    return MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "optimization_result = scipy.optimize.minimize(\n",
    "                      fun=eval_func,\n",
    "#                       fun=lambda x: eval_func(x)[0],\n",
    "                      x0=np.array([1.0 for x in range(preacts.shape[1])]\n",
    "                                  +[0.0 for x in range(preacts.shape[1])]),\n",
    "                      bounds=[(0,None) for x in range(preacts.shape[1])]\n",
    "                              +[(None,None) for x in range(preacts.shape[1])],\n",
    "#                       jac=True,\n",
    "                      method='L-BFGS-B',\n",
    "                      tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 5.192912766460722e-11\n",
       "     jac: array([-0.00993638, -0.00979049, -0.01376561,  0.0016993 , -0.00716579,\n",
       "       -0.04151871, -0.00791228, -0.00620294, -0.01278704, -0.00920676,\n",
       "        0.00711787, -0.00170159,  0.00068763, -0.01562243, -0.00118715,\n",
       "        0.01287408,  0.00064462, -0.00283404,  0.0008278 , -0.00080675])\n",
       " message: 'Optimization terminated successfully'\n",
       "    nfev: 204\n",
       "     nit: 9\n",
       "    njev: 9\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([ 4.61069834e+00,  2.95019820e+00,  2.79173523e+00,  5.90396901e+00,\n",
       "        3.94892438e+00,  1.66745684e+00,  3.70487555e+00,  3.23876667e+00,\n",
       "        1.95357580e+00,  2.41730853e+00, -1.49443554e-01,  1.59860198e-02,\n",
       "        1.87513256e-01, -1.93028018e-01, -5.53625175e-02,  3.24705318e-01,\n",
       "       -1.38296583e-01, -7.68951271e-02,  8.85976762e-02, -3.78795058e-03])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9574786236375985e-10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_func([ 4.61069834e+00,  2.95019820e+00,  2.79173523e+00,  5.90396901e+00,\n",
    "        3.94892438e+00,  1.66745684e+00,  3.70487555e+00,  3.23876667e+00,\n",
    "        1.95357580e+00,  2.41730853e+00, -1.49443554e-01,  1.59860198e-02,\n",
    "        1.87513256e-01, -1.93028018e-01, -5.53625175e-02,  3.24705318e-01,\n",
    "       -1.38296583e-01, -7.68951271e-02,  8.85976762e-02, -3.78795058e-03])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001881617622297771"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ts = 3\n",
    "eval_func([ Ts,  Ts,  Ts,  Ts,\n",
    "        Ts,  Ts,  Ts,  Ts,\n",
    "        Ts,  Ts, 0,  0,\n",
    "        0, 0, 0,  0,\n",
    "       0, 0,  0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "classratio = [5000, 2997, 1796, 1077, 645, 387, 232, 139, 83, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare:\n",
    "# -> preacts. N x C\n",
    "# -> labels. N\n",
    "def eval_func(x):\n",
    "    ws = np.array(x[:int(len(x)/2)])\n",
    "    bs = np.array(x[int(len(x)/2):]) \n",
    "    \n",
    "    ws = np.concatenate((classratio[0]/classratio[0] * ws[None, 0] + np.ones(1),\n",
    "                         classratio[1]/classratio[0] * ws[None, 0] + np.ones(1),\n",
    "                         classratio[2]/classratio[0] * ws[None, 0] + np.ones(1),\n",
    "                         classratio[3]/classratio[0] * ws[None, 0] + np.ones(1),\n",
    "                         classratio[4]/classratio[0] * ws[None, 0] + np.ones(1),\n",
    "                         classratio[5]/classratio[0] * ws[None, 0] + np.ones(1),\n",
    "                         classratio[6]/classratio[0] * ws[None, 0] + np.ones(1),\n",
    "                         classratio[7]/classratio[0] * ws[None, 0] + np.ones(1),\n",
    "                         classratio[8]/classratio[0] * ws[None, 0] + np.ones(1),\n",
    "                         classratio[9]/classratio[0] * ws[None, 0] + np.ones(1)))\n",
    "    vs_logits = preacts/ws[None,:]\n",
    "    exp_vs_logits = np.exp(vs_logits)\n",
    "    sum_exp = np.sum(exp_vs_logits, axis=1, keepdims=True)\n",
    "    AC = np.mean(np.max(exp_vs_logits/sum_exp, axis=1))\n",
    "    preds = np.argmax(preacts, axis = 1)\n",
    "    acc = np.sum(labels == preds) / len(labels)\n",
    "    MC = np.abs(AC-acc)\n",
    "\n",
    "    return MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "optimization_result = scipy.optimize.minimize(\n",
    "                      fun=eval_func,\n",
    "#                       fun=lambda x: eval_func(x)[0],\n",
    "                      x0=np.array([1.0 for x in range(preacts.shape[1])]\n",
    "                                  +[0.0 for x in range(preacts.shape[1])]),\n",
    "                      bounds=[(0,None) for x in range(preacts.shape[1])]\n",
    "                              +[(None,None) for x in range(preacts.shape[1])],\n",
    "#                       jac=True,\n",
    "                      method='L-BFGS-B',\n",
    "                      tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 6.853961842523404e-12\n",
       " hess_inv: <20x20 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([0.00999609, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])\n",
       "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 693\n",
       "      nit: 6\n",
       "     njev: 33\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([11.53481921,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_resultsdir = '/vol/biomedic3/zl9518/ModelEvaluation/LDAM-DRW/cifar10results/'\n",
    "cnn_pred = pd.read_csv(cifar_resultsdir + 'predictions_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.965339351926488e-01\n",
      "0.9909580019290042\n",
      "0.9962229754794684\n"
     ]
    }
   ],
   "source": [
    "kcls = 10\n",
    "targets_all = np.array(cnn_pred[['target_0', 'target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9']])\n",
    "logit_all = np.array(cnn_pred[['logit_0', 'logit_1', 'logit_2', 'logit_3', 'logit_4', 'logit_5', 'logit_6', 'logit_7', 'logit_8', 'logit_9']])\n",
    "preds_all_argmax = np.argmax(logit_all, axis = 1)\n",
    "# acc\n",
    "target_class = np.argmax(targets_all, axis = 1)\n",
    "pred_class = np.argmax(logit_all, axis = 1)\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "prob = softmax(logit_all.transpose(), T = 1).transpose()\n",
    "probmax = np.max(prob, axis = 1)\n",
    "prob_Topt = softmax(logit_all.transpose(), T = 0.6).transpose()\n",
    "prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "print(acc)\n",
    "print(np.mean(probmax))\n",
    "print(np.mean(prob_Toptmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls 0\n",
      "0.5130111524163569\n",
      "0.9225970527876363\n",
      "0.5174702558349566\n",
      "cls 1\n",
      "0.667574931880109\n",
      "0.9465175121023574\n",
      "0.6638625247488893\n",
      "cls 2\n",
      "0.6723577235772358\n",
      "0.8975987002607149\n",
      "0.6747693768252498\n",
      "cls 3\n",
      "0.5485674353598882\n",
      "0.8778312932453294\n",
      "0.5515075198723262\n",
      "cls 4\n",
      "0.7966976264189887\n",
      "0.9152566261328222\n",
      "0.7927198522007158\n",
      "cls 5\n",
      "0.7688504326328801\n",
      "0.8755787630858152\n",
      "0.7727616252283973\n",
      "cls 6\n",
      "0.920881971465629\n",
      "0.9290975108112881\n",
      "0.9200385890090808\n",
      "cls 7\n",
      "0.9548494983277592\n",
      "0.9130334698715659\n",
      "0.9526457191968399\n",
      "cls 8\n",
      "0.9671717171717171\n",
      "0.9070707221184109\n",
      "0.9661278774550892\n",
      "cls 9\n",
      "0.9842696629213483\n",
      "0.9059517630576093\n",
      "0.9824487077408494\n"
     ]
    }
   ],
   "source": [
    "# choose TS for different classes, manually\n",
    "label = 0\n",
    "targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "pred_class = np.argmax(logit_all, axis = 1)[targets_y1]\n",
    "target_class = np.argmax(targets_all, axis = 1)[targets_y1]\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "prob = softmax(logit_all.transpose(), T = 1).transpose()[targets_y1]\n",
    "probmax = np.max(prob, axis = 1)\n",
    "prob_Topt = softmax(logit_all.transpose(), T = 5.0).transpose()[targets_y1]\n",
    "prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "print('cls ' + str(label))\n",
    "print(acc)\n",
    "print(np.mean(probmax))\n",
    "print(np.mean(prob_Toptmax))\n",
    "label = 1\n",
    "targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "pred_class = np.argmax(logit_all, axis = 1)[targets_y1]\n",
    "target_class = np.argmax(targets_all, axis = 1)[targets_y1]\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "prob = softmax(logit_all.transpose(), T = 1).transpose()[targets_y1]\n",
    "probmax = np.max(prob, axis = 1)\n",
    "prob_Topt = softmax(logit_all.transpose(), T = 5.1).transpose()[targets_y1]\n",
    "prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "print('cls ' + str(label))\n",
    "print(acc)\n",
    "print(np.mean(probmax))\n",
    "print(np.mean(prob_Toptmax))\n",
    "label = 2\n",
    "targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "pred_class = np.argmax(logit_all, axis = 1)[targets_y1]\n",
    "target_class = np.argmax(targets_all, axis = 1)[targets_y1]\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "prob = softmax(logit_all.transpose(), T = 1).transpose()[targets_y1]\n",
    "probmax = np.max(prob, axis = 1)\n",
    "prob_Topt = softmax(logit_all.transpose(), T = 3.1).transpose()[targets_y1]\n",
    "prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "print('cls ' + str(label))\n",
    "print(acc)\n",
    "print(np.mean(probmax))\n",
    "print(np.mean(prob_Toptmax))\n",
    "label = 3\n",
    "targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "pred_class = np.argmax(logit_all, axis = 1)[targets_y1]\n",
    "target_class = np.argmax(targets_all, axis = 1)[targets_y1]\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "prob = softmax(logit_all.transpose(), T = 1).transpose()[targets_y1]\n",
    "probmax = np.max(prob, axis = 1)\n",
    "prob_Topt = softmax(logit_all.transpose(), T = 3.8).transpose()[targets_y1]\n",
    "prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "print('cls ' + str(label))\n",
    "print(acc)\n",
    "print(np.mean(probmax))\n",
    "print(np.mean(prob_Toptmax))\n",
    "label = 4\n",
    "targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "pred_class = np.argmax(logit_all, axis = 1)[targets_y1]\n",
    "target_class = np.argmax(targets_all, axis = 1)[targets_y1]\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "prob = softmax(logit_all.transpose(), T = 1).transpose()[targets_y1]\n",
    "probmax = np.max(prob, axis = 1)\n",
    "prob_Topt = softmax(logit_all.transpose(), T = 2.2).transpose()[targets_y1]\n",
    "prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "print('cls ' + str(label))\n",
    "print(acc)\n",
    "print(np.mean(probmax))\n",
    "print(np.mean(prob_Toptmax))\n",
    "label = 5\n",
    "targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "pred_class = np.argmax(logit_all, axis = 1)[targets_y1]\n",
    "target_class = np.argmax(targets_all, axis = 1)[targets_y1]\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "prob = softmax(logit_all.transpose(), T = 1).transpose()[targets_y1]\n",
    "probmax = np.max(prob, axis = 1)\n",
    "prob_Topt = softmax(logit_all.transpose(), T = 1.9).transpose()[targets_y1]\n",
    "prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "print('cls ' + str(label))\n",
    "print(acc)\n",
    "print(np.mean(probmax))\n",
    "print(np.mean(prob_Toptmax))\n",
    "label = 6\n",
    "targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "pred_class = np.argmax(logit_all, axis = 1)[targets_y1]\n",
    "target_class = np.argmax(targets_all, axis = 1)[targets_y1]\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "prob = softmax(logit_all.transpose(), T = 1).transpose()[targets_y1]\n",
    "probmax = np.max(prob, axis = 1)\n",
    "prob_Topt = softmax(logit_all.transpose(), T = 1.1).transpose()[targets_y1]\n",
    "prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "print('cls ' + str(label))\n",
    "print(acc)\n",
    "print(np.mean(probmax))\n",
    "print(np.mean(prob_Toptmax))\n",
    "label = 7\n",
    "targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "pred_class = np.argmax(logit_all, axis = 1)[targets_y1]\n",
    "target_class = np.argmax(targets_all, axis = 1)[targets_y1]\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "prob = softmax(logit_all.transpose(), T = 1).transpose()[targets_y1]\n",
    "probmax = np.max(prob, axis = 1)\n",
    "prob_Topt = softmax(logit_all.transpose(), T = 0.6).transpose()[targets_y1]\n",
    "prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "print('cls ' + str(label))\n",
    "print(acc)\n",
    "print(np.mean(probmax))\n",
    "print(np.mean(prob_Toptmax))\n",
    "label = 8\n",
    "targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "pred_class = np.argmax(logit_all, axis = 1)[targets_y1]\n",
    "target_class = np.argmax(targets_all, axis = 1)[targets_y1]\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "prob = softmax(logit_all.transpose(), T = 1).transpose()[targets_y1]\n",
    "probmax = np.max(prob, axis = 1)\n",
    "prob_Topt = softmax(logit_all.transpose(), T = 0.4).transpose()[targets_y1]\n",
    "prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "print('cls ' + str(label))\n",
    "print(acc)\n",
    "print(np.mean(probmax))\n",
    "print(np.mean(prob_Toptmax))\n",
    "label = 9\n",
    "targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "pred_class = np.argmax(logit_all, axis = 1)[targets_y1]\n",
    "target_class = np.argmax(targets_all, axis = 1)[targets_y1]\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "prob = softmax(logit_all.transpose(), T = 1).transpose()[targets_y1]\n",
    "probmax = np.max(prob, axis = 1)\n",
    "prob_Topt = softmax(logit_all.transpose(), T = 0.2).transpose()[targets_y1]\n",
    "prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "print('cls ' + str(label))\n",
    "print(acc)\n",
    "print(np.mean(probmax))\n",
    "print(np.mean(prob_Toptmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnT = 3.0\n",
    "# learnTs = [5.0, 5.1, 3.1, 3.8, 2.2, 1.9, 1.1, 0.6, 0.4, 0.2]\n",
    "learnThp = 11.53481921\n",
    "learnTs = [1 + classratio[0]/classratio[0] * learnThp,\n",
    "           1 + classratio[1]/classratio[0] * learnThp,\n",
    "           1 + classratio[2]/classratio[0] * learnThp,\n",
    "           1 + classratio[3]/classratio[0] * learnThp,\n",
    "           1 + classratio[4]/classratio[0] * learnThp,\n",
    "           1 + classratio[5]/classratio[0] * learnThp,\n",
    "           1 + classratio[6]/classratio[0] * learnThp,\n",
    "           1 + classratio[7]/classratio[0] * learnThp,\n",
    "           1 + classratio[8]/classratio[0] * learnThp,\n",
    "           1 + classratio[9]/classratio[0] * learnThp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.53481921,\n",
       " 7.913970634474,\n",
       " 5.143307060232,\n",
       " 3.484600057834,\n",
       " 2.48799167809,\n",
       " 1.892795006854,\n",
       " 1.5352156113439999,\n",
       " 1.3206679740379998,\n",
       " 1.191477998886,\n",
       " 1.1153481921]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 19/19 [00:04<00:00,  4.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# bring a test condition here.\n",
    "acc_results = []\n",
    "AC_results = []\n",
    "TS_results = []\n",
    "CSTS_results = []\n",
    "cifar_resultsdir = '/vol/biomedic3/zl9518/ModelEvaluation/LDAM-DRW/cifar10results/'\n",
    "corruptions = ['gaussian_noise', 'shot_noise' , 'impulse_noise', 'defocus_blur', 'glass_blur', \n",
    "               'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast' , 'elastic_transform', \n",
    "               'pixelate', 'jpeg_compression', 'speckle_noise', 'gaussian_blur', 'spatter', 'saturate']\n",
    "\n",
    "for cname in tqdm(corruptions):\n",
    "    csvfilename = cifar_resultsdir + 'predictions_val_' + cname + '.csv'\n",
    "    cnn_pred_all = pd.read_csv(csvfilename)\n",
    "    for severity in range(5):\n",
    "        cnn_pred = cnn_pred_all.iloc[severity * 10000:(severity + 1) * 10000, :]\n",
    "        \n",
    "        kcls = 10\n",
    "        targets_all = np.array(cnn_pred[['target_0', 'target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9']])\n",
    "        logit_all = np.array(cnn_pred[['logit_0', 'logit_1', 'logit_2', 'logit_3', 'logit_4', 'logit_5', 'logit_6', 'logit_7', 'logit_8', 'logit_9']])\n",
    "        preds_all_argmax = np.argmax(logit_all, axis = 1)\n",
    "        # acc\n",
    "        target_class = np.argmax(targets_all, axis = 1)\n",
    "        pred_class = np.argmax(logit_all, axis = 1)\n",
    "        acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "        prob = softmax(logit_all.transpose(), T = 1).transpose()\n",
    "        probmax = np.max(prob, axis = 1)\n",
    "        prob_Topt = softmax(logit_all.transpose(), T = learnT).transpose()\n",
    "        prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "        acc_results.append(acc)\n",
    "        AC_results.append(np.mean(probmax))\n",
    "        TS_results.append(np.mean(prob_Toptmax))\n",
    "        targets_all = []\n",
    "        preds_class_all = []\n",
    "        for label in range(kcls):\n",
    "            preds_all = softmax(logit_all.transpose(), T = learnTs[label]).transpose()\n",
    "            preds_all_max = np.max(preds_all, axis = 1)\n",
    "            targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "            preds_class = preds_all_max[targets_y1]\n",
    "\n",
    "            preds_class_all = np.concatenate((preds_class_all, preds_class), axis=0)\n",
    "        CSTS_results.append(np.mean(preds_class_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC_results:\n",
      "0.31302850098791185\n",
      "TS_results:\n",
      "0.05689427230773313\n",
      "CSTS_results:\n",
      "0.07597527208201493\n"
     ]
    }
   ],
   "source": [
    "print('AC_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(AC_results))))\n",
    "print('TS_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(TS_results))))\n",
    "print('CSTS_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(CSTS_results))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.651, 0.5639, 0.4721, 0.438, 0.3986, 0.6829, 0.6401, 0.5331, 0.4997, 0.425, 0.6382, 0.581, 0.5246, 0.4258, 0.3512, 0.6961, 0.6573, 0.5855, 0.503, 0.3783, 0.3993, 0.4042, 0.4291, 0.3289, 0.3513, 0.5843, 0.5045, 0.4507, 0.4459, 0.401, 0.5696, 0.5354, 0.4922, 0.4521, 0.3986, 0.6483, 0.5721, 0.5854, 0.5653, 0.54, 0.6728, 0.6226, 0.5513, 0.5409, 0.4748, 0.6854, 0.6458, 0.6054, 0.5586, 0.4614, 0.7047, 0.6975, 0.6886, 0.6744, 0.6319, 0.6767, 0.5734, 0.494, 0.3783, 0.1989, 0.6043, 0.5982, 0.5544, 0.4916, 0.4712, 0.6889, 0.6688, 0.6508, 0.5686, 0.4554, 0.6796, 0.637, 0.6214, 0.5974, 0.5686, 0.6801, 0.6137, 0.5785, 0.5091, 0.447, 0.6964, 0.585, 0.5002, 0.4219, 0.3055, 0.6712, 0.6143, 0.5644, 0.6253, 0.5731, 0.6752, 0.6559, 0.6974, 0.6676, 0.623]\n"
     ]
    }
   ],
   "source": [
    "print(acc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8768938289047543, 0.837108389877433, 0.8042482551633682, 0.7924244916383646, 0.7841384748680134, 0.8923598882268036, 0.8734436809775249, 0.8246622929684018, 0.8121906407070694, 0.7910475813026588, 0.8913638637234937, 0.8652425629593042, 0.8376033932662527, 0.7951425246138926, 0.7699623924260166, 0.9086157761566732, 0.9007210888659134, 0.8880728840496118, 0.8758626623043698, 0.8558056324709005, 0.8212118099296088, 0.8268701607727522, 0.825253173017265, 0.8181323275274984, 0.8087014787414917, 0.8949403192655, 0.8828286250172336, 0.8741018981876794, 0.8717841209665826, 0.8672806384667616, 0.8791042151836198, 0.877514365111139, 0.8705219892996149, 0.8658454850547948, 0.8545418469717173, 0.8936421798720414, 0.8581827377220492, 0.8671515599874541, 0.862831326866085, 0.8446643210122553, 0.898355460297235, 0.8780508560404494, 0.8517011558034937, 0.8488903200420435, 0.8157444346081698, 0.9088944492569421, 0.8982663396440106, 0.8891245210000807, 0.8791414812142608, 0.8502583650248956, 0.9116635765290539, 0.9119093835673945, 0.9105395791625922, 0.9063686896733639, 0.89776189662132, 0.9076518813526345, 0.887285790116767, 0.8721803495800085, 0.8412303202184692, 0.7129085644608616, 0.8857658278180829, 0.8883836422533219, 0.8822405133244597, 0.8743002784379923, 0.8675585681218466, 0.898697543977032, 0.8871065780502407, 0.8744634923072474, 0.8387110323331519, 0.8127918013076033, 0.8920618320877127, 0.8780834887342811, 0.8742877887709044, 0.8697643294907337, 0.8637573809855583, 0.895275940018897, 0.8648918226117683, 0.8490311810983745, 0.816015618794116, 0.7937331378366976, 0.9086493411745891, 0.8877120902036176, 0.8775117658652911, 0.867584953973892, 0.8543038363134571, 0.9018729420504842, 0.882876883911297, 0.8657732530674753, 0.8948087452854988, 0.8838529833477294, 0.9026108981441999, 0.8955421860161681, 0.9084305932242418, 0.8974345220611598, 0.8838785021944899]\n"
     ]
    }
   ],
   "source": [
    "print(AC_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6272623038604255, 0.5534199576127247, 0.49592856660379786, 0.4755811393509783, 0.46090196067867084, 0.6624951853480968, 0.6209175830317167, 0.5360764646645102, 0.5105972855138613, 0.47481541594331056, 0.6566998855214617, 0.5978708364307403, 0.5449883124868313, 0.4683213877329503, 0.4287328663616697, 0.7025474934983739, 0.6833189664335477, 0.6521146832761106, 0.6150350974622916, 0.5584527172376893, 0.5180443906866569, 0.5242117509024344, 0.5274041495082346, 0.5030763251929926, 0.4983216465171991, 0.6642034484289119, 0.6311107500413472, 0.604594500465856, 0.6049609087068497, 0.582438374948789, 0.628881696574335, 0.6234775761340446, 0.6025660755026805, 0.5911144536464235, 0.5664231266614487, 0.662864360884118, 0.5851538101902953, 0.6050592338526403, 0.5944865863279252, 0.559570571040717, 0.6751283623859788, 0.631670222704502, 0.5792951566608936, 0.5720105286845472, 0.5215285802284169, 0.7022056279048705, 0.6789984217373237, 0.6541895241185818, 0.6264893006024916, 0.5645988002540947, 0.7089491021802066, 0.7072161655815755, 0.7016169558743469, 0.6925329138220834, 0.669618188973441, 0.6986943436294759, 0.6484765200520074, 0.6058804195014138, 0.5415780980959353, 0.382006633954674, 0.648320621702987, 0.6493314537286095, 0.6329756405763249, 0.6153316266471464, 0.5998002352918853, 0.6762613598399764, 0.6439343226954523, 0.6200795957173272, 0.5536892616936694, 0.5164480700824502, 0.6588634332822759, 0.6278699024141455, 0.6181489119314731, 0.609207990914609, 0.5968197259076382, 0.6637675595358098, 0.6036145748634546, 0.5747919790733901, 0.5196876234673539, 0.48280555509047374, 0.7025786697013413, 0.651110367746249, 0.6193858808410388, 0.5900814854922956, 0.5418569201004599, 0.6823600801654058, 0.6409133509640331, 0.5984038770973242, 0.6671916024657106, 0.635471891850119, 0.6818900479378832, 0.6662261355062253, 0.6999412105991649, 0.671777964801593, 0.6389230890987101]\n"
     ]
    }
   ],
   "source": [
    "print(TS_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5515593057758293, 0.5147871343833836, 0.5008149062271926, 0.5016209112176129, 0.5098223481403296, 0.5763804677074243, 0.5518015893418705, 0.5098372453085749, 0.5025061229433184, 0.5047246561309477, 0.5223176941558256, 0.47345182921535317, 0.4470981478264821, 0.4315057919396966, 0.4466172395773745, 0.5811998603580886, 0.5556437526609505, 0.5169991870143054, 0.4818816601523879, 0.4352473023008024, 0.45943552009165123, 0.44753141161053656, 0.44766669495310873, 0.44274276999000867, 0.44019929037609135, 0.5091688882283092, 0.459974554584511, 0.4249838528141137, 0.42493304953866506, 0.3970805145601816, 0.489504463968607, 0.47996731501157175, 0.4572845857920349, 0.4423207490840934, 0.41620414822817564, 0.5348822535930253, 0.5050190742134401, 0.498455324599794, 0.48891912479360455, 0.4786520633072486, 0.5587701566827356, 0.517923318977829, 0.4814772486880941, 0.4819828871422228, 0.4611307330685745, 0.5754944558670185, 0.5423573671898654, 0.5126516575246939, 0.4861869498490887, 0.4453937756953856, 0.5872750952604685, 0.5819360544943395, 0.5719136197379, 0.5564314013095037, 0.5159371582669371, 0.5686667521041942, 0.500715461415776, 0.45655410790333006, 0.40119998064542506, 0.2661395599385111, 0.5046129963307351, 0.5065395248597607, 0.4860768991023675, 0.46057787166125747, 0.45017689746069917, 0.5599259938770181, 0.5333657345574015, 0.5145370743138457, 0.4609881836809367, 0.4526012548807199, 0.5591614287666865, 0.532479776819471, 0.5207721647368838, 0.5106015412983677, 0.49533617988392287, 0.5783490827259451, 0.5427614658004792, 0.5277468820866378, 0.5044272251828336, 0.4970422555478166, 0.5812365267894068, 0.5160857212260863, 0.48140468938227104, 0.4549105047367006, 0.4164702141906371, 0.5527198927128851, 0.5051769599443101, 0.46883298571653415, 0.5218834338040853, 0.4837907380644957, 0.5603271752452194, 0.5418212456652031, 0.5770443494403867, 0.5403712717256268, 0.4947157240844039]\n"
     ]
    }
   ],
   "source": [
    "print(CSTS_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnTs = [4.71686642,  2.98959056,  2.77322311,  5.46932655,  3.80400751,\n",
    "        1.88290618,  3.47795797,  2.94641951,  1.57841305,  2.1682578]\n",
    "learnBs = [-0.20477415,  0.00760388,  0.17515667, -0.11472634, -0.05703332,\n",
    "        0.24030254, -0.12796915, -0.05191982,  0.11665848,  0.016691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 19/19 [00:06<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# bring a test condition here.\n",
    "acc_results = []\n",
    "AC_results = []\n",
    "TS_results = []\n",
    "CSTS_results = []\n",
    "cifar_resultsdir = '/vol/biomedic3/zl9518/ModelEvaluation/LDAM-DRW/cifar10results/'\n",
    "corruptions = ['gaussian_noise', 'shot_noise' , 'impulse_noise', 'defocus_blur', 'glass_blur', \n",
    "               'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast' , 'elastic_transform', \n",
    "               'pixelate', 'jpeg_compression', 'speckle_noise', 'gaussian_blur', 'spatter', 'saturate']\n",
    "\n",
    "for cname in tqdm(corruptions):\n",
    "    csvfilename = cifar_resultsdir + 'predictions_val_' + cname + '.csv'\n",
    "    cnn_pred_all = pd.read_csv(csvfilename)\n",
    "    for severity in range(5):\n",
    "        cnn_pred = cnn_pred_all.iloc[severity * 10000:(severity + 1) * 10000, :]\n",
    "        \n",
    "        kcls = 10\n",
    "        targets_all = np.array(cnn_pred[['target_0', 'target_1', 'target_2', 'target_3', 'target_4', 'target_5', 'target_6', 'target_7', 'target_8', 'target_9']])\n",
    "        logit_all = np.array(cnn_pred[['logit_0', 'logit_1', 'logit_2', 'logit_3', 'logit_4', 'logit_5', 'logit_6', 'logit_7', 'logit_8', 'logit_9']])\n",
    "        preds_all_argmax = np.argmax(logit_all, axis = 1)\n",
    "        # acc\n",
    "        target_class = np.argmax(targets_all, axis = 1)\n",
    "        pred_class = np.argmax(logit_all, axis = 1)\n",
    "        acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "        prob = softmax(logit_all.transpose(), T = 1).transpose()\n",
    "        probmax = np.max(prob, axis = 1)\n",
    "        prob_Topt = softmax(logit_all.transpose(), T = learnT).transpose()\n",
    "        prob_Toptmax = np.max(prob_Topt, axis = 1)\n",
    "        acc_results.append(acc)\n",
    "        AC_results.append(np.mean(probmax))\n",
    "        TS_results.append(np.mean(prob_Toptmax))\n",
    "        targets_all = []\n",
    "        preds_class_all = []\n",
    "        for label in range(kcls):\n",
    "            preds_all = softmax(logit_all.transpose(), T = learnTs[label], b = learnBs[label]).transpose()\n",
    "            preds_all_max = np.max(preds_all, axis = 1)\n",
    "            targets_y1 = np.where(preds_all_argmax==label)[0]\n",
    "            preds_class = preds_all_max[targets_y1]\n",
    "\n",
    "            preds_class_all = np.concatenate((preds_class_all, preds_class), axis=0)\n",
    "        CSTS_results.append(np.mean(preds_class_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC_results:\n",
      "0.31302850098791185\n",
      "TS_results:\n",
      "0.05689427230773313\n",
      "CSTS_results:\n",
      "0.03841334508990734\n"
     ]
    }
   ],
   "source": [
    "print('AC_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(AC_results))))\n",
    "print('TS_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(TS_results))))\n",
    "print('CSTS_results:')\n",
    "print(np.mean(np.abs(np.array(acc_results)-np.array(CSTS_results))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5875788947728858, 0.5204646531675186, 0.4654268375139067, 0.44335277651920135, 0.4284824833734593, 0.6212016752819854, 0.5842045232670057, 0.5072186050929492, 0.4809168356988884, 0.44418804101216447, 0.5960022621167216, 0.5352650943126578, 0.48645329170128254, 0.41564778213845155, 0.3821654984401672, 0.6462742031422023, 0.617677558593075, 0.5714736959419754, 0.5162749238165109, 0.42896973750342715, 0.45234401104659866, 0.45325999394406724, 0.46037321316891855, 0.426001794653303, 0.42908892647841423, 0.5871628564833832, 0.5380724314977314, 0.4997654420433724, 0.4996178540931898, 0.4663074006256311, 0.556290736602417, 0.5359314914204976, 0.5054922742511131, 0.4810467459667444, 0.446541279507937, 0.6003385525162502, 0.5275727557680069, 0.5397518581150964, 0.5245830364042148, 0.49956673276257313, 0.6201225700450186, 0.575795161417209, 0.5284962974419752, 0.5224225208615519, 0.48133309046367095, 0.6435570062770808, 0.6113541580493025, 0.5771491573956364, 0.539903937504163, 0.4638901441478924, 0.6546757876143341, 0.6512741965560885, 0.643819463711831, 0.6317437978868858, 0.60010257582849, 0.6366086622593342, 0.5626175648577584, 0.502094497058946, 0.41627657267558527, 0.275059150137433, 0.5776878533359296, 0.5773302308064925, 0.5489468508445421, 0.5165685386887938, 0.5006159047728321, 0.623458735932637, 0.5942312743420727, 0.5710259200262403, 0.5088348092202022, 0.48497307698324166, 0.6045073917660626, 0.5693781800615291, 0.5571144499670445, 0.5438516581774455, 0.5268365035209226, 0.6220223126301418, 0.5690290659773368, 0.5427535047257758, 0.4907813551315989, 0.4524444354032002, 0.6463108999597369, 0.5701185262597546, 0.5185916847540724, 0.46938797582168934, 0.39180339908444306, 0.6234956252288216, 0.5784869307524352, 0.5297184246744444, 0.6037768516679233, 0.5696399306091813, 0.6234292737148168, 0.604569468605241, 0.6468046698980257, 0.6173578549089832, 0.5815588669343728]\n"
     ]
    }
   ],
   "source": [
    "print(CSTS_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IW",
   "language": "python",
   "name": "iw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
