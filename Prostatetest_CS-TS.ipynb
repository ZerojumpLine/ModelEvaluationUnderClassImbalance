{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, T):\n",
    "    x = x / T\n",
    "    f = np.exp(x - np.max(x, axis = 0))  # shift values\n",
    "    return f / f.sum(axis = 0)\n",
    "\n",
    "def ComputMetric(ACTUAL, PREDICTED):\n",
    "    ACTUAL = ACTUAL.flatten()\n",
    "    PREDICTED = PREDICTED.flatten()\n",
    "    idxp = ACTUAL == True\n",
    "    idxn = ACTUAL == False\n",
    "\n",
    "    tp = np.sum(ACTUAL[idxp] == PREDICTED[idxp])\n",
    "    tn = np.sum(ACTUAL[idxn] == PREDICTED[idxn])\n",
    "    fp = np.sum(idxn) - tn\n",
    "    fn = np.sum(idxp) - tp\n",
    "    FPR = fp / (fp + tn)\n",
    "    if tp == 0 :\n",
    "        dice = 0\n",
    "        Precision = 0\n",
    "        Sensitivity = 0\n",
    "    else:\n",
    "        dice = 2 * tp / (2 * tp + fp + fn)\n",
    "        Precision = tp / (tp + fp)\n",
    "        Sensitivity = tp / (tp + fn)\n",
    "    return dice, Sensitivity, Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_tensor(inp, axes, keepdim=False):\n",
    "    axes = np.unique(axes).astype(int)\n",
    "    if keepdim:\n",
    "        for ax in axes:\n",
    "            inp = inp.sum(int(ax), keepdim=True)\n",
    "    else:\n",
    "        for ax in sorted(axes, reverse=True):\n",
    "            inp = inp.sum(int(ax))\n",
    "    return inp\n",
    "\n",
    "def get_tp_fp_fn(net_output, gt, axes=None, mask=None, square=False):\n",
    "    \"\"\"\n",
    "    net_output must be (b, c, x, y(, z)))\n",
    "    gt must be a label map (shape (b, 1, x, y(, z)) OR shape (b, x, y(, z))) or one hot encoding (b, c, x, y(, z))\n",
    "    if mask is provided it must have shape (b, 1, x, y(, z)))\n",
    "    :param net_output:\n",
    "    :param gt:\n",
    "    :param axes:\n",
    "    :param mask: mask must be 1 for valid pixels and 0 for invalid pixels\n",
    "    :param square: if True then fp, tp and fn will be squared before summation\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        axes = tuple(range(2, len(net_output.size())))\n",
    "\n",
    "    shp_x = net_output.shape\n",
    "    shp_y = gt.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if len(shp_x) != len(shp_y):\n",
    "            gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n",
    "\n",
    "        if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n",
    "            # if this is the case then gt is probably already a one hot encoding\n",
    "            y_onehot = gt\n",
    "        else:\n",
    "            gt = gt.long()\n",
    "            y_onehot = torch.zeros(shp_x)\n",
    "            if net_output.device.type == \"cuda\":\n",
    "                y_onehot = y_onehot.cuda(net_output.device.index)\n",
    "            y_onehot.scatter_(1, gt, 1)\n",
    "\n",
    "    tp = net_output * y_onehot\n",
    "    fp = net_output * (1 - y_onehot)\n",
    "    fn = (1 - net_output) * y_onehot\n",
    "\n",
    "    if mask is not None:\n",
    "        tp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(tp, dim=1)), dim=1)\n",
    "        fp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fp, dim=1)), dim=1)\n",
    "        fn = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fn, dim=1)), dim=1)\n",
    "\n",
    "    if square:\n",
    "        tp = tp ** 2\n",
    "        fp = fp ** 2\n",
    "        fn = fn ** 2\n",
    "\n",
    "    tp = sum_tensor(tp, axes, keepdim=False)\n",
    "    fp = sum_tensor(fp, axes, keepdim=False)\n",
    "    fn = sum_tensor(fn, axes, keepdim=False)\n",
    "\n",
    "    return tp, fp, fn\n",
    "\n",
    "\n",
    "def SoftDiceLoss(x, y, loss_mask = None, smooth = 1e-5, batch_dice = False):\n",
    "    '''\n",
    "    Batch_dice means that we want to calculate the dsc of all batch\n",
    "    It would make more sense for small patchsize, aka DeepMedic based training.\n",
    "    '''\n",
    "    shp_x = x.shape\n",
    "    square = False\n",
    "\n",
    "    axes = [0] + list(range(2, len(shp_x)))\n",
    "    tp, fp, fn = get_tp_fp_fn(x, y, axes, loss_mask, square)\n",
    "    dc = (2 * tp + smooth) / (2 * tp + fp + fn + smooth)\n",
    "    dc_process = dc\n",
    "\n",
    "    return dc_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultpath = '/vol/biomedic3/zl9518/ModelEvaluation/output/prostate/prostateval/'\n",
    "prostatevalpath = '/vol/biomedic3/zl9518/Prostatedata/datafiletestB/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatafiletsImgc1 = prostatevalpath + 'seg-eval.txt'\n",
    "Imgfiletsc1 = open(DatafiletsImgc1)\n",
    "Imgreadc1 = Imgfiletsc1.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "probs_all = []\n",
    "preds_class_all = []\n",
    "targets_all = []\n",
    "for Imgnamec1 in tqdm(Imgreadc1):\n",
    "    knamelist = Imgnamec1.split(\"/\")\n",
    "    kname = knamelist[-1][0:6]\n",
    "    \n",
    "    cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "    cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "    cls0read = nib.load(cls0filename)\n",
    "    cls1read = nib.load(cls1filename)\n",
    "    cls0logit = cls0read.get_fdata()\n",
    "    cls1logit = cls1read.get_fdata()\n",
    "    GTread = nib.load(Imgnamec1)\n",
    "    GTimg = GTread.get_fdata()\n",
    "    imgshape = GTimg.shape\n",
    "    cls0flatten = cls0logit.flatten()\n",
    "    cls1flatten = cls1logit.flatten()\n",
    "    clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "    GTflatten = GTimg.flatten()\n",
    "    probflatten = softmax(clsflatten, T = 1.6)\n",
    "    \n",
    "    pred_class = np.argmax(probflatten, axis = 0)\n",
    "    preds_class_all = np.concatenate((preds_class_all, pred_class), axis=0)\n",
    "    targets_all = np.concatenate((targets_all, GTflatten), axis=0)\n",
    "    probmax = np.max(probflatten, axis = 0)\n",
    "    probs_all = np.concatenate((probs_all, probmax), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9960332029006206\n",
      "0.9960515118056786\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(targets_all == preds_class_all) / len(targets_all))\n",
    "print(np.mean(probs_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# probs_all_c0 = []\n",
    "# preds_class_all_c0 = []\n",
    "# targets_all_c0 = []\n",
    "# probs_all_c1 = []\n",
    "# preds_class_all_c1 = []\n",
    "# targets_all_c1 = []\n",
    "softDSCs = []\n",
    "realDSCs = []\n",
    "for Imgnamec1 in tqdm(Imgreadc1):\n",
    "    knamelist = Imgnamec1.split(\"/\")\n",
    "    kname = knamelist[-1][0:6]\n",
    "    \n",
    "    cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "    cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "    cls0read = nib.load(cls0filename)\n",
    "    cls1read = nib.load(cls1filename)\n",
    "    cls0logit = cls0read.get_fdata()\n",
    "    cls1logit = cls1read.get_fdata()\n",
    "    GTread = nib.load(Imgnamec1)\n",
    "    GTimg = GTread.get_fdata()\n",
    "    imgshape = GTimg.shape\n",
    "    cls0flatten = cls0logit.flatten()\n",
    "    cls1flatten = cls1logit.flatten()\n",
    "    clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "    GTflatten = GTimg.flatten()\n",
    "    probflatten = softmax(clsflatten, T = 1.0)\n",
    "    \n",
    "    preds_all_argmax = np.argmax(clsflatten, axis = 0)\n",
    "    # for cls 0, BG class \n",
    "#     targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "#     probflatten_c0 = softmax(clsflatten[:, targets_y1], T = 1.6)\n",
    "#     pred_class_c0 = np.argmax(probflatten_c0, axis = 0)\n",
    "#     preds_class_all_c0 = np.concatenate((preds_class_all_c0, pred_class_c0), axis=0)\n",
    "    \n",
    "#     targets_all_c0 = np.concatenate((targets_all_c0, GTflatten[targets_y1]), axis=0)\n",
    "#     probmax_c0 = np.max(probflatten_c0, axis = 0)\n",
    "#     probs_all_c0 = np.concatenate((probs_all_c0, probmax_c0), axis=0)\n",
    "    \n",
    "#     # for cls 1, FG class\n",
    "#     targets_y1 = np.where(preds_all_argmax==1)[0]\n",
    "#     probflatten_c1 = softmax(clsflatten[:, targets_y1], T = 1.7)\n",
    "#     pred_class_c1 = np.argmax(probflatten_c1, axis = 0)\n",
    "#     preds_class_all_c1 = np.concatenate((preds_class_all_c1, pred_class_c1), axis=0)\n",
    "    \n",
    "#     targets_all_c1 = np.concatenate((targets_all_c1, GTflatten[targets_y1]), axis=0)\n",
    "#     probmax_c1 = np.max(probflatten_c1, axis = 0)\n",
    "#     probs_all_c1 = np.concatenate((probs_all_c1, probmax_c1), axis=0)\n",
    "    \n",
    "    # for cls 0, BG class \n",
    "    targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "    probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = 1.8)\n",
    "    # for cls 1, FG class\n",
    "    targets_y1 = np.where(preds_all_argmax==1)[0]\n",
    "    # 1.7\n",
    "    probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = 1.3)\n",
    "    probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "    probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "    GTimgf = np.argmax(probr, axis = 0)\n",
    "    GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "    \n",
    "    softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "    softDSCs.append(softDSC[1].numpy())\n",
    "\n",
    "    realDSC, _, _ = ComputMetric(GTimg, np.argmax(probr, axis = 0))\n",
    "    realDSCs.append(realDSC)\n",
    "    \n",
    "#     softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "#     softDSCs.append(softDSC[0].numpy())\n",
    "\n",
    "#     realDSC, _, _ = ComputMetric(1-GTimg, 1-np.argmax(probr, axis = 0))\n",
    "#     realDSCs.append(realDSC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8927934005334531\n",
      "0.8925794874268455\n"
     ]
    }
   ],
   "source": [
    "# print(np.sum(targets_all_c0 == preds_class_all_c0) / len(targets_all_c0))\n",
    "# print(np.mean(probs_all_c0))\n",
    "# print(np.sum(targets_all_c1 == preds_class_all_c1) / len(targets_all_c1))\n",
    "# print(np.mean(probs_all_c1))\n",
    "print(np.mean(softDSCs))\n",
    "print(np.mean(realDSCs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 83/83 [17:52<00:00, 12.92s/it]\n"
     ]
    }
   ],
   "source": [
    "# 84 conditions\n",
    "softDSCs_AC = []\n",
    "softDSCs_TS = []\n",
    "softDSCs_CSTS = []\n",
    "realDSCs = []\n",
    "for kcon in tqdm(range(1, 84)):\n",
    "    softDSC_FG_AC = []\n",
    "    softDSC_FG_TS = []\n",
    "    softDSC_FG_CSTS = []\n",
    "    realDSC_FG = []\n",
    "    resultpath = '/vol/biomedic3/zl9518/ModelEvaluation/output/prostate/prostattestcondition_' + str(kcon) + '/'\n",
    "    for Imgnamec1 in Imgreadc1:\n",
    "        knamelist = Imgnamec1.split(\"/\")\n",
    "        kname = knamelist[-1][0:6]\n",
    "\n",
    "        cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "        cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "        cls0read = nib.load(cls0filename)\n",
    "        cls1read = nib.load(cls1filename)\n",
    "        cls0logit = cls0read.get_fdata()\n",
    "        cls1logit = cls1read.get_fdata()\n",
    "        GTread = nib.load(Imgnamec1)\n",
    "        GTimg = GTread.get_fdata()\n",
    "        imgshape = GTimg.shape\n",
    "        cls0flatten = cls0logit.flatten()\n",
    "        cls1flatten = cls1logit.flatten()\n",
    "        clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "        GTflatten = GTimg.flatten()\n",
    "        # By AC\n",
    "        probflatten = softmax(clsflatten, T = 1.0)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_AC.append(softDSC[1].numpy())\n",
    "        # By TS\n",
    "        probflatten = softmax(clsflatten, T = 1.6)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_TS.append(softDSC[1].numpy())\n",
    "        # By CSTS\n",
    "        preds_all_argmax = np.argmax(clsflatten, axis = 0)\n",
    "        # for cls 0, BG class \n",
    "        targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = 1.6)\n",
    "        # for cls 1, FG class\n",
    "        targets_y1 = np.where(preds_all_argmax==1)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = 1.9)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_CSTS.append(softDSC[1].numpy())\n",
    "\n",
    "        realDSC, _, _ = ComputMetric(GTimg, np.argmax(probr, axis = 0))\n",
    "        realDSC_FG.append(realDSC)\n",
    "        \n",
    "    softDSCs_AC.append(np.mean(np.array(softDSC_FG_AC)))\n",
    "    softDSCs_TS.append(np.mean(np.array(softDSC_FG_TS)))\n",
    "    softDSCs_CSTS.append(np.mean(np.array(softDSC_FG_CSTS)))\n",
    "    realDSCs.append(np.mean(np.array(realDSC_FG)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC_results:\n",
      "8.682389850061455e-02\n",
      "TS_results:\n",
      "0.03662467820391148\n",
      "CSTS_results:\n",
      "0.030188914963328883\n"
     ]
    }
   ],
   "source": [
    "print('AC_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_AC))))\n",
    "print('TS_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_TS))))\n",
    "print('CSTS_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_CSTS))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8457301025307677, 0.870852084028978, 0.828521585768393, 0.790703746725564, 0.7586812862096527, 0.7557484783931, 0.8172327417988589, 0.6604643235449457, 0.8391672071049449, 0.629645911710675, 0.8541350026276865, 0.8736883469998509, 0.8538392221470215, 0.843655497285545, 0.8472068280655369, 0.8415826376847552, 0.8719698924620335, 0.8669337478504607, 0.8188883956186596, 0.8289616381345647, 0.7512113795312175, 0.7984512037339606, 0.8258757147417111, 0.7808367447866433, 0.8216387475687809, 0.7407959047695183, 0.8082450924634974, 0.7488012437878321, 0.8813964100757584, 0.8449041600923041, 0.8723101712065781, 0.7438437175087971, 0.7690050430372952, 0.8036237249343758, 0.6054180714311662, 0.594775255065044, 0.8655259284098629, 0.8193493642947048, 0.8471036691597765, 0.8195559172815617, 0.8942332191332024, 0.886877812107558, 0.8949294033819303, 0.8655104773584853, 0.8947390346757661, 0.8509641068080747, 0.8916376091423593, 0.8932068281575198, 0.8886573243066662, 0.894043014237129, 0.8841409920497802, 0.8945585277579324, 0.8915872253807999, 0.8935827270797739, 0.8900613019952767, 0.8954535279095417, 0.8892877072755626, 0.8968215735063524, 0.8925794874268455, 0.8925794874268455, 0.8925794874268455, 0.8925794874268455, 0.8925794874268455, 0.8925794874268455, 0.8924648761656288, 0.8925377580298599, 0.8933089801905837, 0.8926561620676898, 0.895421017289985, 0.8927403679919301, 0.8880752189634069, 0.8667071812675555, 0.8374601769085613, 0.872159526969176, 0.8836511356030041, 0.8232106744297741, 0.8933175164598876, 0.8939974918047922, 0.8932180514356667, 0.8756891702461991, 0.8520728368902251, 0.8584788186194494, 0.7989908175918564]\n"
     ]
    }
   ],
   "source": [
    "print(realDSCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8702601597709705, 0.5146653097008377, 0.8480215327272811, 0.5908085240964449, 0.8264001936756081, 0.6342678277254019, 0.8345615597667864, 0.5867774324229249, 0.85772956165116, 0.6167862937446114, 0.8521182339839264, 0.8575666788241805, 0.8527545252174573, 0.8428973075397586, 0.8417549487698229, 0.8349566964011158, 0.8578925801637183, 0.8584899804114092, 0.8267156726489603, 0.8333627412373723, 0.8031375233899904, 0.804884168253175, 0.7016966360899005, 0.7076394225892692, 0.6931981986187961, 0.7069555182484295, 0.6910189719938, 0.6990766821542791, 0.884241670106767, 0.8724038918449899, 0.881455116354347, 0.8079843958477673, 0.8019315536063948, 0.8742810081639518, 0.7909066784034626, 0.7881487166712728, 0.8819808030414004, 0.8398840819676755, 0.8476036888578763, 0.8749042700385592, 0.8943149119064289, 0.8811824274440486, 0.8971423201322979, 0.8743659631943549, 0.8963994944678092, 0.8730522898548019, 0.8873102334621038, 0.8907318155979626, 0.8830484328724968, 0.8927361059143235, 0.8789044846837335, 0.8939776867018494, 0.8883166636518492, 0.8902278821615365, 0.8869977196980254, 0.8926193013389533, 0.8858143070442257, 0.8952288805148519, 0.8892028757077803, 0.8892028632948616, 0.8892028564038608, 0.8892028705556887, 0.8892028599259627, 0.8892028654686085, 0.889172612770017, 0.8892291214967163, 0.8907698290214532, 0.8892919820768401, 0.8948091588070115, 0.8893519883359211, 0.8821941541658722, 0.8641726761836643, 0.8460978949830471, 0.8733163992478389, 0.8867256201051188, 0.8600283054203463, 0.8903111596159052, 0.8912502779839228, 0.8928382502948592, 0.8702540856976023, 0.8538099903537255, 0.8598185460997918, 0.8750005620266634]\n"
     ]
    }
   ],
   "source": [
    "print(softDSCs_CSTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8835471295601198, 0.5258335863516532, 0.8602712728706216, 0.6040689439126108, 0.8387758084349235, 0.6488667443956512, 0.8456610477582845, 0.6014554518893156, 0.8679129574772471, 0.6320750203002559, 0.8657178181548257, 0.8710232990631166, 0.8666605127123574, 0.8567054651659335, 0.8557832475513896, 0.8487327174578325, 0.8713144750506485, 0.8719290850322177, 0.8404998610537417, 0.8471405132886558, 0.8174492827650279, 0.8189720914299443, 0.714555385273155, 0.7209860308769293, 0.7061699634392125, 0.7208145823338781, 0.7041825529076107, 0.7127840956294553, 0.8978366338835755, 0.8863333634773973, 0.8951645034481196, 0.8221395568237708, 0.8156616965187382, 0.8886309350575242, 0.8054426054643553, 0.80327195186624, 0.8957340932524286, 0.8541531310847461, 0.861875316462742, 0.8890754977267946, 0.9078407384788715, 0.8947121365690469, 0.9106804102357661, 0.8880808734255303, 0.909963748066318, 0.8869371628147238, 0.9008249236473975, 0.9042523766369943, 0.8965621530310551, 0.9062604532972527, 0.8924297312581013, 0.9075050016068256, 0.9018390640894356, 0.9037408005656669, 0.9005267742878352, 0.9061269138278707, 0.8993444209320425, 0.9087401367437394, 0.9027205297991078, 0.9027205177288202, 0.9027205105462419, 0.9027205250909487, 0.9027205138254718, 0.9027205203432631, 0.9026918646744966, 0.9027472600402631, 0.9042920439415164, 0.902809478817127, 0.9083212786017943, 0.9028692145032358, 0.8957171612422765, 0.8778490110973427, 0.8600226022990277, 0.8871049252038317, 0.90047294857632, 0.8741419158087795, 0.9038341160499502, 0.9048289659624846, 0.9065386564173243, 0.8839031490987305, 0.8677129925851826, 0.8738293117294388, 0.8893350682481149]\n"
     ]
    }
   ],
   "source": [
    "print(softDSCs_TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9445208141411179, 0.5600351926555271, 0.931730127079436, 0.6528295465927425, 0.9158539060827395, 0.7136134168357384, 0.9246074382786308, 0.6644763539333387, 0.9389497001221697, 0.7066098338452236, 0.9275612026510706, 0.9325569574687153, 0.9328646004932912, 0.9269801658772193, 0.9270234060337872, 0.9238830251708064, 0.9326770866378464, 0.9336464948378751, 0.9172174173486736, 0.9205507685038764, 0.9035785475003083, 0.9033867852464283, 0.7677991683602265, 0.77648857500991, 0.7670021114181449, 0.7822310609348627, 0.7681708070921458, 0.7782648221080334, 0.9547345456520384, 0.9456113594412106, 0.9535450027183474, 0.9004201920300152, 0.8979303404342277, 0.9448680173310867, 0.8859718451761012, 0.8879338421392813, 0.9540584116065987, 0.9288409827503431, 0.9366174510538441, 0.9459088235601767, 0.9619089739592205, 0.9532975605133911, 0.9635967070577143, 0.9466395431589174, 0.9636146188932045, 0.9455708263766514, 0.9578893452463093, 0.9599190227327112, 0.9549463403474387, 0.961062565393781, 0.9515175398065029, 0.9617788075917636, 0.9583956927335651, 0.9597772130758943, 0.9575104902053905, 0.961441181446807, 0.9569452845233041, 0.9630999484301854, 0.9590364093650277, 0.9590363994342577, 0.959036392308124, 0.9590364062231991, 0.9590363982022062, 0.9590364032240967, 0.95900104638466, 0.9590458197604365, 0.9599731055521014, 0.959094514675478, 0.9618567287645607, 0.9591395174937857, 0.9558408131210936, 0.9444166262204436, 0.9337935699114303, 0.9489966481305195, 0.9567010093569644, 0.9379683409277753, 0.9596489660013671, 0.9594923408111391, 0.960642535589748, 0.9481430046919568, 0.9352942657281476, 0.942777893434001, 0.9461562874272953]\n"
     ]
    }
   ],
   "source": [
    "print(softDSCs_AC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 5/5 [00:47<00:00,  9.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# 5 conditions\n",
    "domainlist = ['A', 'C', 'D', 'E', 'F']\n",
    "softDSCs_AC = []\n",
    "softDSCs_TS = []\n",
    "softDSCs_CSTS = []\n",
    "realDSCs = []\n",
    "for kcon in tqdm(domainlist):\n",
    "    softDSC_FG_AC = []\n",
    "    softDSC_FG_TS = []\n",
    "    softDSC_FG_CSTS = []\n",
    "    realDSC_FG = []\n",
    "    resultpath = '/vol/biomedic3/zl9518/ModelEvaluation/output/prostate/prostattestcondition_' + kcon + '/'\n",
    "    \n",
    "    prostatevalpath = '/vol/biomedic3/zl9518/Prostatedata/datafiletest' + kcon + '/'\n",
    "    DatafiletsImgc1 = prostatevalpath + 'seg-eval.txt'\n",
    "    Imgfiletsc1 = open(DatafiletsImgc1)\n",
    "    Imgreadc1 = Imgfiletsc1.read().splitlines()\n",
    "    \n",
    "    for Imgnamec1 in Imgreadc1:\n",
    "        knamelist = Imgnamec1.split(\"/\")\n",
    "        kname = knamelist[-1][0:6]\n",
    "\n",
    "        cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "        cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "        cls0read = nib.load(cls0filename)\n",
    "        cls1read = nib.load(cls1filename)\n",
    "        cls0logit = cls0read.get_fdata()\n",
    "        cls1logit = cls1read.get_fdata()\n",
    "        GTread = nib.load(Imgnamec1)\n",
    "        GTimg = GTread.get_fdata()\n",
    "        imgshape = GTimg.shape\n",
    "        cls0flatten = cls0logit.flatten()\n",
    "        cls1flatten = cls1logit.flatten()\n",
    "        clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "        GTflatten = GTimg.flatten()\n",
    "        # By AC\n",
    "        probflatten = softmax(clsflatten, T = 1.0)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_AC.append(softDSC[1].numpy())\n",
    "        # By TS\n",
    "        probflatten = softmax(clsflatten, T = 1.6)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_TS.append(softDSC[1].numpy())\n",
    "        # By CSTS\n",
    "        preds_all_argmax = np.argmax(clsflatten, axis = 0)\n",
    "        # for cls 0, BG class \n",
    "        targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = 1.8)\n",
    "        # for cls 1, FG class\n",
    "        targets_y1 = np.where(preds_all_argmax==1)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = 1.3)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_CSTS.append(softDSC[1].numpy())\n",
    "\n",
    "        realDSC, _, _ = ComputMetric(GTimg, np.argmax(probr, axis = 0))\n",
    "        realDSC_FG.append(realDSC)\n",
    "        \n",
    "    softDSCs_AC.append(np.mean(np.array(softDSC_FG_AC)))\n",
    "    softDSCs_TS.append(np.mean(np.array(softDSC_FG_TS)))\n",
    "    softDSCs_CSTS.append(np.mean(np.array(softDSC_FG_CSTS)))\n",
    "    realDSCs.append(np.mean(np.array(realDSC_FG)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC_results:\n",
      "0.18734415411981173\n",
      "TS_results:\n",
      "0.09247324744821413\n",
      "CSTS_results:\n",
      "0.07853095452815757\n"
     ]
    }
   ],
   "source": [
    "print('AC_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_AC))))\n",
    "print('TS_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_TS))))\n",
    "print('CSTS_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_CSTS))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.831820639295538e-01, 0.6361422807072967, 0.6095476370292467, 0.8351399018424807, 0.7657602931920688]\n"
     ]
    }
   ],
   "source": [
    "print(realDSCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.807022927996315, 0.7456312568567052, 0.7655065414273087, 0.8600237527812303, 0.8139539348801582]\n"
     ]
    }
   ],
   "source": [
    "print(softDSCs_TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7898991981831605, 0.7305824462124744, 0.7515516465391919, 0.8458572287013559, 0.799992836418788]\n"
     ]
    }
   ],
   "source": [
    "print(softDSCs_CSTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8903888833710243, 0.8646945640943136, 0.8701191490312503, 0.9339760285393177, 0.9073143222637996]\n"
     ]
    }
   ],
   "source": [
    "print(softDSCs_AC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IW",
   "language": "python",
   "name": "iw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
