{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zejuli/opt/anaconda3/envs/modeleval/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, T):\n",
    "    x = x / T\n",
    "    f = np.exp(x - np.max(x, axis = 0))  # shift values\n",
    "    return f / f.sum(axis = 0)\n",
    "\n",
    "def ComputMetric(ACTUAL, PREDICTED):\n",
    "    ACTUAL = ACTUAL.flatten()\n",
    "    PREDICTED = PREDICTED.flatten()\n",
    "    idxp = ACTUAL == True\n",
    "    idxn = ACTUAL == False\n",
    "\n",
    "    tp = np.sum(ACTUAL[idxp] == PREDICTED[idxp])\n",
    "    tn = np.sum(ACTUAL[idxn] == PREDICTED[idxn])\n",
    "    fp = np.sum(idxn) - tn\n",
    "    fn = np.sum(idxp) - tp\n",
    "    FPR = fp / (fp + tn)\n",
    "    if tp == 0 :\n",
    "        dice = 0\n",
    "        Precision = 0\n",
    "        Sensitivity = 0\n",
    "    else:\n",
    "        dice = 2 * tp / (2 * tp + fp + fn)\n",
    "        Precision = tp / (tp + fp)\n",
    "        Sensitivity = tp / (tp + fn)\n",
    "    return dice, Sensitivity, Precision\n",
    "\n",
    "def sum_tensor(inp, axes, keepdim=False):\n",
    "    axes = np.unique(axes).astype(int)\n",
    "    if keepdim:\n",
    "        for ax in axes:\n",
    "            inp = inp.sum(int(ax), keepdim=True)\n",
    "    else:\n",
    "        for ax in sorted(axes, reverse=True):\n",
    "            inp = inp.sum(int(ax))\n",
    "    return inp\n",
    "\n",
    "def get_tp_fp_fn(net_output, gt, axes=None, mask=None, square=False):\n",
    "    \"\"\"\n",
    "    net_output must be (b, c, x, y(, z)))\n",
    "    gt must be a label map (shape (b, 1, x, y(, z)) OR shape (b, x, y(, z))) or one hot encoding (b, c, x, y(, z))\n",
    "    if mask is provided it must have shape (b, 1, x, y(, z)))\n",
    "    :param net_output:\n",
    "    :param gt:\n",
    "    :param axes:\n",
    "    :param mask: mask must be 1 for valid pixels and 0 for invalid pixels\n",
    "    :param square: if True then fp, tp and fn will be squared before summation\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        axes = tuple(range(2, len(net_output.size())))\n",
    "\n",
    "    shp_x = net_output.shape\n",
    "    shp_y = gt.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if len(shp_x) != len(shp_y):\n",
    "            gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n",
    "\n",
    "        if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n",
    "            # if this is the case then gt is probably already a one hot encoding\n",
    "            y_onehot = gt\n",
    "        else:\n",
    "            gt = gt.long()\n",
    "            y_onehot = torch.zeros(shp_x)\n",
    "            if net_output.device.type == \"cuda\":\n",
    "                y_onehot = y_onehot.cuda(net_output.device.index)\n",
    "            y_onehot.scatter_(1, gt, 1)\n",
    "\n",
    "    tp = net_output * y_onehot\n",
    "    fp = net_output * (1 - y_onehot)\n",
    "    fn = (1 - net_output) * y_onehot\n",
    "\n",
    "    if mask is not None:\n",
    "        tp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(tp, dim=1)), dim=1)\n",
    "        fp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fp, dim=1)), dim=1)\n",
    "        fn = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fn, dim=1)), dim=1)\n",
    "\n",
    "    if square:\n",
    "        tp = tp ** 2\n",
    "        fp = fp ** 2\n",
    "        fn = fn ** 2\n",
    "\n",
    "    tp = sum_tensor(tp, axes, keepdim=False)\n",
    "    fp = sum_tensor(fp, axes, keepdim=False)\n",
    "    fn = sum_tensor(fn, axes, keepdim=False)\n",
    "\n",
    "    return tp, fp, fn\n",
    "\n",
    "\n",
    "def SoftDiceLoss(x, y, loss_mask = None, smooth = 1e-5, batch_dice = False):\n",
    "    '''\n",
    "    Batch_dice means that we want to calculate the dsc of all batch\n",
    "    It would make more sense for small patchsize, aka DeepMedic based training.\n",
    "    '''\n",
    "    shp_x = x.shape\n",
    "    square = False\n",
    "\n",
    "    axes = [0] + list(range(2, len(shp_x)))\n",
    "    tp, fp, fn = get_tp_fp_fn(x, y, axes, loss_mask, square)\n",
    "    dc = (2 * tp + smooth) / (2 * tp + fp + fn + smooth)\n",
    "    dc_process = dc\n",
    "\n",
    "    return dc_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-Specific Temperature-Scaling (CS TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultpath = './data/Prostateresults/prostateval/'\n",
    "prostatevalpath = './data/Prostateresults/'\n",
    "DatafiletsImgc1 = prostatevalpath + 'seg-eval.txt'\n",
    "Imgfiletsc1 = open(DatafiletsImgc1)\n",
    "Imgreadc1 = Imgfiletsc1.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature-Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:04<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "probs_all = []\n",
    "preds_class_all = []\n",
    "targets_all = []\n",
    "logits_all = []\n",
    "for Imgnamec1 in tqdm(Imgreadc1):\n",
    "    knamelist = Imgnamec1.split(\"/\")\n",
    "    kname = knamelist[-1][0:6]\n",
    "    \n",
    "    cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "    cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "    cls0read = nib.load(cls0filename)\n",
    "    cls1read = nib.load(cls1filename)\n",
    "    cls0logit = cls0read.get_fdata()\n",
    "    cls1logit = cls1read.get_fdata()\n",
    "    GTread = nib.load(Imgnamec1)\n",
    "    GTimg = GTread.get_fdata()\n",
    "    imgshape = GTimg.shape\n",
    "    cls0flatten = cls0logit.flatten()\n",
    "    cls1flatten = cls1logit.flatten()\n",
    "    clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "    GTflatten = GTimg.flatten()\n",
    "    probflatten = softmax(clsflatten, T = 1.6)\n",
    "    \n",
    "    pred_class = np.argmax(probflatten, axis = 0)\n",
    "    preds_class_all = np.concatenate((preds_class_all, pred_class), axis=0)\n",
    "    targets_all = np.concatenate((targets_all, GTflatten), axis=0)\n",
    "    probmax = np.max(probflatten, axis = 0)\n",
    "    probs_all = np.concatenate((probs_all, probmax), axis=0)\n",
    "    \n",
    "    if len(logits_all) == 0:\n",
    "        logits_all = clsflatten\n",
    "    else:\n",
    "        logits_all = np.concatenate((logits_all, clsflatten), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preacts = logits_all.T\n",
    "labels = targets_all\n",
    "preds = np.argmax(preacts, axis = 1)\n",
    "acc = np.sum(labels == preds) / len(labels)\n",
    "def eval_func(x):\n",
    "   \n",
    "    ts_logits = preacts/x\n",
    "    exp_ts_logits = np.exp(ts_logits)\n",
    "    sum_exp = np.sum(exp_ts_logits, axis=1, keepdims=True)\n",
    "    AC = np.mean(np.max(exp_ts_logits/sum_exp, axis=1))\n",
    "    MC = np.abs(AC-acc)\n",
    "\n",
    "    return MC\n",
    "optimization_result = scipy.optimize.minimize(\n",
    "                          fun=eval_func,\n",
    "                          x0=np.array([1.0]),\n",
    "                          method='Nelder-Mead',\n",
    "                          tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6034124374389669\n"
     ]
    }
   ],
   "source": [
    "LearedTemp = optimization_result.x[0]\n",
    "print(LearedTemp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-Specific Temperature-Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the first step, align the background with acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> preacts. N x C\n",
    "# -> labels. N\n",
    "preacts = logits_all.T\n",
    "labels = targets_all\n",
    "preds_all_argmax = np.argmax(preacts, axis = 1)\n",
    "targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "pred_class = np.argmax(preacts, axis = 1)[targets_y1]\n",
    "target_class = targets_all[targets_y1]\n",
    "\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "def eval_func(x):\n",
    "    \n",
    "    prob_Topt = softmax(logits_all, T = x).transpose()[targets_y1]\n",
    "    AC = np.mean(np.max(prob_Topt, axis = 1))\n",
    "\n",
    "    MC = np.abs(AC-acc)\n",
    "\n",
    "    return MC\n",
    "\n",
    "optimization_result = scipy.optimize.minimize(\n",
    "                      fun=eval_func,\n",
    "                      x0=np.array([1.0]),\n",
    "                      method='Nelder-Mead',\n",
    "                      tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5503941535949726\n"
     ]
    }
   ],
   "source": [
    "LearedTempBG = optimization_result.x[0]\n",
    "print(LearedTempBG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the second step, align the foreground with DSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_func(x):\n",
    "    softDSCs = []\n",
    "    realDSCs = []\n",
    "    for Imgnamec1 in Imgreadc1:\n",
    "        knamelist = Imgnamec1.split(\"/\")\n",
    "        kname = knamelist[-1][0:6]\n",
    "\n",
    "        cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "        cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "        cls0read = nib.load(cls0filename)\n",
    "        cls1read = nib.load(cls1filename)\n",
    "        cls0logit = cls0read.get_fdata()\n",
    "        cls1logit = cls1read.get_fdata()\n",
    "        GTread = nib.load(Imgnamec1)\n",
    "        GTimg = GTread.get_fdata()\n",
    "        imgshape = GTimg.shape\n",
    "        cls0flatten = cls0logit.flatten()\n",
    "        cls1flatten = cls1logit.flatten()\n",
    "        clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "        GTflatten = GTimg.flatten()\n",
    "        probflatten = softmax(clsflatten, T = 1.0)\n",
    "\n",
    "        preds_all_argmax = np.argmax(clsflatten, axis = 0)\n",
    "\n",
    "        # for cls 0, BG class \n",
    "        targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = LearedTempBG)\n",
    "        # for cls 1, FG class\n",
    "        targets_y1 = np.where(preds_all_argmax==1)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = x)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSCs.append(softDSC[1].numpy())\n",
    "\n",
    "        realDSC, _, _ = ComputMetric(GTimg, np.argmax(probr, axis = 0))\n",
    "        realDSCs.append(realDSC)\n",
    "    MC = np.abs(np.mean(softDSCs) - np.mean(realDSCs))\n",
    "\n",
    "    return MC\n",
    "        \n",
    "optimization_result = scipy.optimize.minimize(\n",
    "                      fun=eval_func,\n",
    "                      x0=np.array([1.0]),\n",
    "                      method='Nelder-Mead',\n",
    "                      bounds=[(0,None)],\n",
    "                      tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9221460342407244\n"
     ]
    }
   ],
   "source": [
    "LearedTempFG = optimization_result.x[0]\n",
    "print(LearedTempFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# 5 conditions\n",
    "domainlist = ['A']\n",
    "softDSCs_AC = []\n",
    "softDSCs_TS = []\n",
    "softDSCs_CSTS = []\n",
    "realDSCs = []\n",
    "for kcon in tqdm(domainlist):\n",
    "    softDSC_FG_AC = []\n",
    "    softDSC_FG_TS = []\n",
    "    softDSC_FG_CSTS = []\n",
    "    realDSC_FG = []\n",
    "    resultpath = prostatevalpath + '/prostattestcondition_' + kcon + '/'\n",
    "    \n",
    "    DatafiletsImgc1 = prostatevalpath + 'seg-test' + kcon + '.txt'\n",
    "    Imgfiletsc1 = open(DatafiletsImgc1)\n",
    "    Imgreadc1 = Imgfiletsc1.read().splitlines()\n",
    "    \n",
    "    for Imgnamec1 in Imgreadc1:\n",
    "        knamelist = Imgnamec1.split(\"/\")\n",
    "        kname = knamelist[-1][0:6]\n",
    "\n",
    "        cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "        cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "        cls0read = nib.load(cls0filename)\n",
    "        cls1read = nib.load(cls1filename)\n",
    "        cls0logit = cls0read.get_fdata()\n",
    "        cls1logit = cls1read.get_fdata()\n",
    "        GTread = nib.load(Imgnamec1)\n",
    "        GTimg = GTread.get_fdata()\n",
    "        imgshape = GTimg.shape\n",
    "        cls0flatten = cls0logit.flatten()\n",
    "        cls1flatten = cls1logit.flatten()\n",
    "        clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "        GTflatten = GTimg.flatten()\n",
    "        # By AC\n",
    "        probflatten = softmax(clsflatten, T = 1.0)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_AC.append(softDSC[1].numpy())\n",
    "        # By TS\n",
    "        probflatten = softmax(clsflatten, T = LearedTemp)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_TS.append(softDSC[1].numpy())\n",
    "        # By CSTS\n",
    "        preds_all_argmax = np.argmax(clsflatten, axis = 0)\n",
    "        # for cls 0, BG class \n",
    "        targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = LearedTempBG)\n",
    "        # for cls 1, FG class\n",
    "        targets_y1 = np.where(preds_all_argmax==1)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = LearedTempFG)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_CSTS.append(softDSC[1].numpy())\n",
    "\n",
    "        realDSC, _, _ = ComputMetric(GTimg, np.argmax(probr, axis = 0))\n",
    "        realDSC_FG.append(realDSC)\n",
    "        \n",
    "    softDSCs_AC.append(np.mean(np.array(softDSC_FG_AC)))\n",
    "    softDSCs_TS.append(np.mean(np.array(softDSC_FG_TS)))\n",
    "    softDSCs_CSTS.append(np.mean(np.array(softDSC_FG_CSTS)))\n",
    "    realDSCs.append(np.mean(np.array(realDSC_FG)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC_results:\n",
      "0.1049066211781956\n",
      "TS_results:\n",
      "0.015096730900921562\n",
      "CSTS_results:\n",
      "0.004232643061958363\n"
     ]
    }
   ],
   "source": [
    "print('AC_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_AC))))\n",
    "print('TS_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_TS))))\n",
    "print('CSTS_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_CSTS))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-Specific Difference of Confidences (CS DoC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultpath = './data/Prostateresults/prostateval/'\n",
    "prostatevalpath = './data/Prostateresults/'\n",
    "DatafiletsImgc1 = prostatevalpath + 'seg-eval.txt'\n",
    "Imgfiletsc1 = open(DatafiletsImgc1)\n",
    "Imgreadc1 = Imgfiletsc1.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference of Confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "probs_all = []\n",
    "preds_class_all = []\n",
    "targets_all = []\n",
    "\n",
    "softDSCs = []\n",
    "realDSCs = []\n",
    "for Imgnamec1 in tqdm(Imgreadc1):\n",
    "    knamelist = Imgnamec1.split(\"/\")\n",
    "    kname = knamelist[-1][0:6]\n",
    "    \n",
    "    cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "    cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "    cls0read = nib.load(cls0filename)\n",
    "    cls1read = nib.load(cls1filename)\n",
    "    cls0logit = cls0read.get_fdata()\n",
    "    cls1logit = cls1read.get_fdata()\n",
    "    GTread = nib.load(Imgnamec1)\n",
    "    GTimg = GTread.get_fdata()\n",
    "    imgshape = GTimg.shape\n",
    "    cls0flatten = cls0logit.flatten()\n",
    "    cls1flatten = cls1logit.flatten()\n",
    "    clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "    GTflatten = GTimg.flatten()\n",
    "    probflatten = softmax(clsflatten, T = 1.0)\n",
    "    \n",
    "    pred_class = np.argmax(probflatten, axis = 0)\n",
    "    preds_class_all = np.concatenate((preds_class_all, pred_class), axis=0)\n",
    "    targets_all = np.concatenate((targets_all, GTflatten), axis=0)\n",
    "    probmax = np.max(probflatten, axis = 0)\n",
    "    probs_all = np.concatenate((probs_all, probmax), axis=0)\n",
    "\n",
    "acc = np.sum(targets_all == preds_class_all) / len(targets_all)\n",
    "mean_prob = np.mean(probs_all)\n",
    "DoC = mean_prob - acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0022837051173588696\n"
     ]
    }
   ],
   "source": [
    "print(DoC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-Specific Difference of Confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "probs_all = []\n",
    "preds_class_all = []\n",
    "targets_all = []\n",
    "softDSCs = []\n",
    "realDSCs = []\n",
    "for Imgnamec1 in tqdm(Imgreadc1):\n",
    "    knamelist = Imgnamec1.split(\"/\")\n",
    "    kname = knamelist[-1][0:6]\n",
    "    \n",
    "    cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "    cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "    cls0read = nib.load(cls0filename)\n",
    "    cls1read = nib.load(cls1filename)\n",
    "    cls0logit = cls0read.get_fdata()\n",
    "    cls1logit = cls1read.get_fdata()\n",
    "    GTread = nib.load(Imgnamec1)\n",
    "    GTimg = GTread.get_fdata()\n",
    "    imgshape = GTimg.shape\n",
    "    cls0flatten = cls0logit.flatten()\n",
    "    cls1flatten = cls1logit.flatten()\n",
    "    clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "    GTflatten = GTimg.flatten()\n",
    "    probflatten = softmax(clsflatten, T = 1.0)\n",
    "    \n",
    "    pred_class = np.argmax(probflatten, axis = 0)\n",
    "    preds_class_all = np.concatenate((preds_class_all, pred_class), axis=0)\n",
    "    targets_all = np.concatenate((targets_all, GTflatten), axis=0)\n",
    "    probmax = np.max(probflatten, axis = 0)\n",
    "    probs_all = np.concatenate((probs_all, probmax), axis=0)\n",
    "\n",
    "    preds_all_argmax = np.argmax(clsflatten, axis = 0)\n",
    "\n",
    "    # for cls 0, BG class \n",
    "    targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "    probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = 1.0)\n",
    "    # for cls 1, FG class\n",
    "    targets_y1 = np.where(preds_all_argmax==1)[0]\n",
    "    probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = 1.0)\n",
    "    probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "    probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "    GTimgf = np.argmax(probr, axis = 0)\n",
    "    GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "    \n",
    "    softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "    softDSCs.append(softDSC[1].numpy())\n",
    "\n",
    "    realDSC, _, _ = ComputMetric(GTimg, np.argmax(probr, axis = 0))\n",
    "    realDSCs.append(realDSC)\n",
    "\n",
    "msoftDSC = np.mean(softDSCs)\n",
    "mrealDSC = np.mean(realDSCs)\n",
    "CS_DoC = msoftDSC - mrealDSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06645691983623936\n"
     ]
    }
   ],
   "source": [
    "print(CS_DoC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# 5 conditions\n",
    "domainlist = ['A']\n",
    "softDSCs_AC = []\n",
    "softDSCs_DoC = []\n",
    "softDSCs_CSDoC = []\n",
    "realDSCs = []\n",
    "for kcon in tqdm(domainlist):\n",
    "    softDSC_FG_AC = []\n",
    "    softDSC_FG_DoC = []\n",
    "    softDSC_FG_CSDoC = []\n",
    "    realDSC_FG = []\n",
    "    resultpath = prostatevalpath + '/prostattestcondition_' + kcon + '/'\n",
    "    \n",
    "    DatafiletsImgc1 = prostatevalpath + 'seg-test' + kcon + '.txt'\n",
    "    Imgfiletsc1 = open(DatafiletsImgc1)\n",
    "    Imgreadc1 = Imgfiletsc1.read().splitlines()\n",
    "    for Imgnamec1 in Imgreadc1:\n",
    "        knamelist = Imgnamec1.split(\"/\")\n",
    "        kname = knamelist[-1][0:6]\n",
    "\n",
    "        cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "        cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "        cls0read = nib.load(cls0filename)\n",
    "        cls1read = nib.load(cls1filename)\n",
    "        cls0logit = cls0read.get_fdata()\n",
    "        cls1logit = cls1read.get_fdata()\n",
    "        GTread = nib.load(Imgnamec1)\n",
    "        GTimg = GTread.get_fdata()\n",
    "        imgshape = GTimg.shape\n",
    "        cls0flatten = cls0logit.flatten()\n",
    "        cls1flatten = cls1logit.flatten()\n",
    "        clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "        GTflatten = GTimg.flatten()\n",
    "        # By AC\n",
    "        probflatten = softmax(clsflatten, T = 1.0)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_AC.append(softDSC[1].numpy())\n",
    "        # By DoC\n",
    "        probflattens = softmax(clsflatten, T = 1.0)\n",
    "        # calculate the diff\n",
    "        \n",
    "        preds_all_argmax = np.argmax(clsflatten, axis = 0)\n",
    "\n",
    "        probflattens[0, np.where(preds_all_argmax == 0)] = probflattens[0, np.where(preds_all_argmax == 0)] - DoC\n",
    "        probflattens[1, np.where(preds_all_argmax == 0)] = probflattens[1, np.where(preds_all_argmax == 0)] + DoC\n",
    "        probflattens[0, np.where((1-preds_all_argmax) == 0)] = probflattens[0, np.where((1-preds_all_argmax) == 0)] + DoC\n",
    "        probflattens[1, np.where((1-preds_all_argmax) == 0)] = probflattens[1, np.where((1-preds_all_argmax) == 0)] - DoC\n",
    "        probflattens = np.clip(probflattens, 0, 1)\n",
    "        \n",
    "        \n",
    "        probrs = probflattens.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probrs_tensor = torch.tensor(probrs[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probrs_tensor, GT_tensor)\n",
    "        softDSC_FG_DoC.append(softDSC[1].numpy())\n",
    "        # By CSDoC\n",
    "        preds_all_argmax = np.argmax(clsflatten, axis = 0)\n",
    "        # for cls 0, BG class \n",
    "        targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = 1.0)\n",
    "        \n",
    "        # for cls 1, FG class\n",
    "        targets_y1 = np.where(preds_all_argmax==1)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = 1.0)\n",
    "        \n",
    "        probflatten = np.clip(probflatten, 0, 1)\n",
    "        \n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "#         softDSC_FG_CSDoC.append(softDSC[1].numpy())\n",
    "        softDSC_FG_CSDoC.append(softDSC[1].numpy() - CS_DoC)\n",
    "\n",
    "        realDSC, _, _ = ComputMetric(GTimg, np.argmax(probr, axis = 0))\n",
    "        realDSC_FG.append(realDSC)\n",
    "        \n",
    "    softDSCs_AC.append(np.mean(np.array(softDSC_FG_AC)))\n",
    "    softDSCs_DoC.append(np.mean(np.array(softDSC_FG_DoC)))\n",
    "    softDSCs_CSDoC.append(np.mean(np.array(softDSC_FG_CSDoC)))\n",
    "    realDSCs.append(np.mean(np.array(realDSC_FG)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC_results:\n",
      "0.1049066211781956\n",
      "DoC_results:\n",
      "0.06883680087590571\n",
      "CSDoC_results:\n",
      "0.038449701341956244\n"
     ]
    }
   ],
   "source": [
    "print('AC_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_AC))))\n",
    "print('DoC_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_DoC))))\n",
    "print('CSDoC_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_CSDoC))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-Specific Average Thresholded Confidence (CS ATC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultpath = './data/Prostateresults/prostateval/'\n",
    "prostatevalpath = './data/Prostateresults/'\n",
    "DatafiletsImgc1 = prostatevalpath + 'seg-eval.txt'\n",
    "Imgfiletsc1 = open(DatafiletsImgc1)\n",
    "Imgreadc1 = Imgfiletsc1.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Thresholded Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "probs_all = []\n",
    "preds_class_all = []\n",
    "targets_all = []\n",
    "for Imgnamec1 in tqdm(Imgreadc1):\n",
    "    knamelist = Imgnamec1.split(\"/\")\n",
    "    kname = knamelist[-1][0:6]\n",
    "    \n",
    "    cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "    cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "    cls0read = nib.load(cls0filename)\n",
    "    cls1read = nib.load(cls1filename)\n",
    "    cls0logit = cls0read.get_fdata()\n",
    "    cls1logit = cls1read.get_fdata()\n",
    "    GTread = nib.load(Imgnamec1)\n",
    "    GTimg = GTread.get_fdata()\n",
    "    imgshape = GTimg.shape\n",
    "    cls0flatten = cls0logit.flatten()\n",
    "    cls1flatten = cls1logit.flatten()\n",
    "    clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "    GTflatten = GTimg.flatten()\n",
    "    probflatten = softmax(clsflatten, T = 1.0)\n",
    "    \n",
    "    pred_class = np.argmax(probflatten, axis = 0)\n",
    "    preds_class_all = np.concatenate((preds_class_all, pred_class), axis=0)\n",
    "    targets_all = np.concatenate((targets_all, GTflatten), axis=0)\n",
    "    probmax = np.max(probflatten, axis = 0)\n",
    "    probs_all = np.concatenate((probs_all, probmax), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_func(x):\n",
    "    \n",
    "    prob = softmax(logits_all.transpose(), T = 1).transpose()\n",
    "    probmax = np.max(prob, axis = 1)\n",
    "    acc_appr = np.sum(probs_all > x) / len(targets_all)\n",
    "    \n",
    "    preds = np.argmax(preacts, axis = 1)\n",
    "    acc = np.sum(targets_all == preds_class_all) / len(targets_all)\n",
    "    \n",
    "    MC = np.abs(acc_appr-acc)\n",
    "\n",
    "    return MC\n",
    "optimization_result = scipy.optimize.minimize(\n",
    "                          fun=eval_func,\n",
    "                          x0=np.array([1.0]),\n",
    "                          method='Nelder-Mead',\n",
    "                          tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8772399902343748\n"
     ]
    }
   ],
   "source": [
    "LearedThreshold = optimization_result.x[0]\n",
    "print(LearedThreshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-Specific Average Thresholded Confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the first step, align the background with acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> preacts. N x C\n",
    "# -> labels. N\n",
    "preacts = logits_all.T\n",
    "labels = targets_all\n",
    "preds_all_argmax = np.argmax(preacts, axis = 1)\n",
    "targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "pred_class = np.argmax(preacts, axis = 1)[targets_y1]\n",
    "target_class = targets_all[targets_y1]\n",
    "\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "def eval_func(x):\n",
    "    \n",
    "    prob_Topt = softmax(logits_all, T = 1).transpose()[targets_y1]\n",
    "    acc_appr = np.sum(prob_Topt > x) / len(targets_y1)\n",
    "\n",
    "    MC = np.abs(acc_appr-acc)\n",
    "\n",
    "    return MC\n",
    "\n",
    "optimization_result = scipy.optimize.minimize(\n",
    "                      fun=eval_func,\n",
    "                      x0=np.array([1.0]),\n",
    "                      method='Nelder-Mead',\n",
    "                      tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8566162109375\n"
     ]
    }
   ],
   "source": [
    "LearedThresholdBG = optimization_result.x[0]\n",
    "print(LearedThresholdBG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the second step, align the foreground with DSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_func(x):\n",
    "    softDSCs = []\n",
    "    realDSCs = []\n",
    "    for Imgnamec1 in Imgreadc1:\n",
    "        knamelist = Imgnamec1.split(\"/\")\n",
    "        kname = knamelist[-1][0:6]\n",
    "\n",
    "        cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "        cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "        cls0read = nib.load(cls0filename)\n",
    "        cls1read = nib.load(cls1filename)\n",
    "        cls0logit = cls0read.get_fdata()\n",
    "        cls1logit = cls1read.get_fdata()\n",
    "        GTread = nib.load(Imgnamec1)\n",
    "        GTimg = GTread.get_fdata()\n",
    "        imgshape = GTimg.shape\n",
    "        cls0flatten = cls0logit.flatten()\n",
    "        cls1flatten = cls1logit.flatten()\n",
    "        clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "        GTflatten = GTimg.flatten()\n",
    "        probflatten = softmax(clsflatten, T = 1.0)\n",
    "\n",
    "        preds_all_argmax = np.argmax(clsflatten, axis = 0)\n",
    "\n",
    "        # for cls 0, BG class \n",
    "        targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "        probflattens = probflatten\n",
    "        probflattens[:, targets_y1] = probflatten[:, targets_y1] > LearedThresholdBG\n",
    "        probflattens = probflattens.astype(float)\n",
    "        # for cls 1, FG class\n",
    "        targets_y1 = np.where(preds_all_argmax==1)[0]\n",
    "        probflattens[:, targets_y1] = probflatten[:, targets_y1] > x\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probrs = probflattens.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probrs[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSCs.append(softDSC[1].numpy())\n",
    "\n",
    "        realDSC, _, _ = ComputMetric(GTimg, np.argmax(probr, axis = 0))\n",
    "        realDSCs.append(realDSC)\n",
    "    MC = np.abs(np.mean(softDSCs) - np.mean(realDSCs))\n",
    "\n",
    "    return MC\n",
    "        \n",
    "optimization_result = scipy.optimize.minimize(\n",
    "                      fun=eval_func,\n",
    "                      x0=np.array([1.0]),\n",
    "                      method='Nelder-Mead',\n",
    "                      bounds=[(0,None)],\n",
    "                      tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9695383071899413\n"
     ]
    }
   ],
   "source": [
    "LearedThresholdFG = optimization_result.x[0]\n",
    "print(LearedThresholdFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "# 5 conditions\n",
    "domainlist = ['A']\n",
    "softDSCs_AC = []\n",
    "softDSCs_ATC = []\n",
    "softDSCs_CSATC = []\n",
    "realDSCs = []\n",
    "for kcon in tqdm(domainlist):\n",
    "    softDSC_FG_AC = []\n",
    "    softDSC_FG_ATC = []\n",
    "    softDSC_FG_CSATC = []\n",
    "    realDSC_FG = []\n",
    "    resultpath = prostatevalpath + '/prostattestcondition_' + kcon + '/'\n",
    "    \n",
    "    DatafiletsImgc1 = prostatevalpath + 'seg-test' + kcon + '.txt'\n",
    "    Imgfiletsc1 = open(DatafiletsImgc1)\n",
    "    Imgreadc1 = Imgfiletsc1.read().splitlines()\n",
    "    for Imgnamec1 in Imgreadc1:\n",
    "        knamelist = Imgnamec1.split(\"/\")\n",
    "        kname = knamelist[-1][0:6]\n",
    "\n",
    "        cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "        cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "        cls0read = nib.load(cls0filename)\n",
    "        cls1read = nib.load(cls1filename)\n",
    "        cls0logit = cls0read.get_fdata()\n",
    "        cls1logit = cls1read.get_fdata()\n",
    "        GTread = nib.load(Imgnamec1)\n",
    "        GTimg = GTread.get_fdata()\n",
    "        imgshape = GTimg.shape\n",
    "        cls0flatten = cls0logit.flatten()\n",
    "        cls1flatten = cls1logit.flatten()\n",
    "        clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "        GTflatten = GTimg.flatten()\n",
    "        # By AC\n",
    "        probflatten = softmax(clsflatten, T = 1.0)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_AC.append(softDSC[1].numpy())\n",
    "        # By ATC\n",
    "        probflatten = softmax(clsflatten, T = 1.0)\n",
    "        probflattens = probflatten > LearedThreshold\n",
    "        probflattens = probflattens.astype(float)\n",
    "        \n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        probrs = probflattens.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probrs[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_ATC.append(softDSC[1].numpy())\n",
    "        # By CSATC\n",
    "        preds_all_argmax = np.argmax(clsflatten, axis = 0)\n",
    "        # for cls 0, BG class \n",
    "        targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = 1.0)\n",
    "        probflattens[:, targets_y1] = probflatten[:, targets_y1] > LearedThresholdBG\n",
    "        # for cls 1, FG class\n",
    "        targets_y1 = np.where(preds_all_argmax==1)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = 1.0)\n",
    "        probflattens[:, targets_y1] = probflatten[:, targets_y1] > LearedThresholdFG\n",
    "        probflattens = probflattens.astype(float)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probrs = probflattens.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probrs[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_CSATC.append(softDSC[1].numpy())\n",
    "\n",
    "        realDSC, _, _ = ComputMetric(GTimg, np.argmax(probr, axis = 0))\n",
    "        realDSC_FG.append(realDSC)\n",
    "        \n",
    "    softDSCs_AC.append(np.mean(np.array(softDSC_FG_AC)))\n",
    "    softDSCs_ATC.append(np.mean(np.array(softDSC_FG_ATC)))\n",
    "    softDSCs_CSATC.append(np.mean(np.array(softDSC_FG_CSATC)))\n",
    "    realDSCs.append(np.mean(np.array(realDSC_FG)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC_results:\n",
      "0.1049066211781956\n",
      "ATC_results:\n",
      "0.10018981168974028\n",
      "CSATC_results:\n",
      "0.021114346746849644\n"
     ]
    }
   ],
   "source": [
    "print('AC_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_AC))))\n",
    "print('ATC_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_ATC))))\n",
    "print('CSATC_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_CSATC))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-Specific Temperature-Scaling Average Thresholded Confidence (CS TS-ATC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultpath = './data/Prostateresults/prostateval/'\n",
    "prostatevalpath = './data/Prostateresults/'\n",
    "DatafiletsImgc1 = prostatevalpath + 'seg-eval.txt'\n",
    "Imgfiletsc1 = open(DatafiletsImgc1)\n",
    "Imgreadc1 = Imgfiletsc1.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature-Scaling Average Thresholded Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> preacts. N x C\n",
    "# -> labels. N\n",
    "preacts = logits_all.T\n",
    "labels = targets_all\n",
    "preds_all_argmax = np.argmax(preacts, axis = 1)\n",
    "targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "pred_class = np.argmax(preacts, axis = 1)[targets_y1]\n",
    "target_class = targets_all[targets_y1]\n",
    "\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "def eval_func(x):\n",
    "    \n",
    "    prob_Topt = softmax(logits_all, T = LearedTemp).transpose()[targets_y1]\n",
    "    acc_appr = np.sum(prob_Topt > x) / len(targets_y1)\n",
    "\n",
    "    MC = np.abs(acc_appr-acc)\n",
    "\n",
    "    return MC\n",
    "\n",
    "optimization_result = scipy.optimize.minimize(\n",
    "                      fun=eval_func,\n",
    "                      x0=np.array([1.0]),\n",
    "                      method='Nelder-Mead',\n",
    "                      tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7530212402343748\n"
     ]
    }
   ],
   "source": [
    "LearedThreshold = optimization_result.x[0]\n",
    "print(LearedThreshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-Specific Temperature-Scaling Average Thresholded Confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the first step, align the background with acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> preacts. N x C\n",
    "# -> labels. N\n",
    "preacts = logits_all.T\n",
    "labels = targets_all\n",
    "preds_all_argmax = np.argmax(preacts, axis = 1)\n",
    "targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "pred_class = np.argmax(preacts, axis = 1)[targets_y1]\n",
    "target_class = targets_all[targets_y1]\n",
    "\n",
    "acc = np.sum(pred_class == target_class) / len(target_class)\n",
    "def eval_func(x):\n",
    "    \n",
    "    prob_Topt = softmax(logits_all, T = LearedTempBG).transpose()[targets_y1]\n",
    "    acc_appr = np.sum(prob_Topt > x) / len(targets_y1)\n",
    "\n",
    "    MC = np.abs(acc_appr-acc)\n",
    "\n",
    "    return MC\n",
    "\n",
    "optimization_result = scipy.optimize.minimize(\n",
    "                      fun=eval_func,\n",
    "                      x0=np.array([1.0]),\n",
    "                      method='Nelder-Mead',\n",
    "                      tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7600433349609372\n"
     ]
    }
   ],
   "source": [
    "LearedThresholdBG = optimization_result.x[0]\n",
    "print(LearedThresholdBG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the second step, align the foreground with DSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_func(x):\n",
    "    softDSCs = []\n",
    "    realDSCs = []\n",
    "    for Imgnamec1 in Imgreadc1:\n",
    "        knamelist = Imgnamec1.split(\"/\")\n",
    "        kname = knamelist[-1][0:6]\n",
    "\n",
    "        cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "        cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "        cls0read = nib.load(cls0filename)\n",
    "        cls1read = nib.load(cls1filename)\n",
    "        cls0logit = cls0read.get_fdata()\n",
    "        cls1logit = cls1read.get_fdata()\n",
    "        GTread = nib.load(Imgnamec1)\n",
    "        GTimg = GTread.get_fdata()\n",
    "        imgshape = GTimg.shape\n",
    "        cls0flatten = cls0logit.flatten()\n",
    "        cls1flatten = cls1logit.flatten()\n",
    "        clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "        GTflatten = GTimg.flatten()\n",
    "        probflatten = softmax(clsflatten, T = LearedTemp)\n",
    "\n",
    "        preds_all_argmax = np.argmax(clsflatten, axis = 0)\n",
    "        \n",
    "        #\n",
    "        targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = LearedTempBG)\n",
    "        targets_y1 = np.where(preds_all_argmax==1)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = LearedTempFG)\n",
    "\n",
    "        # for cls 0, BG class \n",
    "        targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "        probflattens = probflatten\n",
    "        probflattens[:, targets_y1] = probflatten[:, targets_y1] > LearedThresholdBG\n",
    "        probflattens = probflattens.astype(float)\n",
    "        # for cls 1, FG class\n",
    "        targets_y1 = np.where(preds_all_argmax==1)[0]\n",
    "        probflattens[:, targets_y1] = probflatten[:, targets_y1] > x\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probrs = probflattens.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probrs[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSCs.append(softDSC[1].numpy())\n",
    "\n",
    "        realDSC, _, _ = ComputMetric(GTimg, np.argmax(probr, axis = 0))\n",
    "        realDSCs.append(realDSC)\n",
    "    MC = np.abs(np.mean(softDSCs) - np.mean(realDSCs))\n",
    "\n",
    "    return MC\n",
    "        \n",
    "optimization_result = scipy.optimize.minimize(\n",
    "                      fun=eval_func,\n",
    "                      x0=np.array([1.0]),\n",
    "                      method='Nelder-Mead',\n",
    "                      bounds=[(0,None)],\n",
    "                      tol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8581798553466796\n"
     ]
    }
   ],
   "source": [
    "LearedThresholdFG = optimization_result.x[0]\n",
    "print(LearedThresholdFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# 5 conditions\n",
    "domainlist = ['A']\n",
    "softDSCs_AC = []\n",
    "softDSCs_ATC = []\n",
    "softDSCs_CSATC = []\n",
    "realDSCs = []\n",
    "for kcon in tqdm(domainlist):\n",
    "    softDSC_FG_AC = []\n",
    "    softDSC_FG_ATC = []\n",
    "    softDSC_FG_CSATC = []\n",
    "    realDSC_FG = []\n",
    "    resultpath = prostatevalpath + '/prostattestcondition_' + kcon + '/'\n",
    "    \n",
    "    DatafiletsImgc1 = prostatevalpath + 'seg-test' + kcon + '.txt'\n",
    "    Imgfiletsc1 = open(DatafiletsImgc1)\n",
    "    Imgreadc1 = Imgfiletsc1.read().splitlines()\n",
    "    for Imgnamec1 in Imgreadc1:\n",
    "        knamelist = Imgnamec1.split(\"/\")\n",
    "        kname = knamelist[-1][0:6]\n",
    "\n",
    "        cls0filename = resultpath + '/results/pred_' + kname + 'cls0_prob.nii.gz'\n",
    "        cls1filename = resultpath + '/results/pred_' + kname + 'cls1_prob.nii.gz'\n",
    "        cls0read = nib.load(cls0filename)\n",
    "        cls1read = nib.load(cls1filename)\n",
    "        cls0logit = cls0read.get_fdata()\n",
    "        cls1logit = cls1read.get_fdata()\n",
    "        GTread = nib.load(Imgnamec1)\n",
    "        GTimg = GTread.get_fdata()\n",
    "        imgshape = GTimg.shape\n",
    "        cls0flatten = cls0logit.flatten()\n",
    "        cls1flatten = cls1logit.flatten()\n",
    "        clsflatten = np.stack((cls0flatten, cls1flatten))\n",
    "        GTflatten = GTimg.flatten()\n",
    "        # By AC\n",
    "        probflatten = softmax(clsflatten, T = 1.0)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probr[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_AC.append(softDSC[1].numpy())\n",
    "        # By ATC\n",
    "        probflatten = softmax(clsflatten, T = LearedTemp)\n",
    "        probflattens = probflatten > LearedThreshold\n",
    "        probflattens = probflattens.astype(float)\n",
    "        \n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        probrs = probflattens.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probrs[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_ATC.append(softDSC[1].numpy())\n",
    "        # By CSATC\n",
    "        preds_all_argmax = np.argmax(clsflatten, axis = 0)\n",
    "        # for cls 0, BG class \n",
    "        targets_y1 = np.where(preds_all_argmax==0)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = LearedTempBG)\n",
    "        probflattens[:, targets_y1] = probflatten[:, targets_y1] > LearedThresholdBG\n",
    "        # for cls 1, FG class\n",
    "        targets_y1 = np.where(preds_all_argmax==1)[0]\n",
    "        probflatten[:, targets_y1] = softmax(clsflatten[:, targets_y1], T = LearedTempFG)\n",
    "        probflattens[:, targets_y1] = probflatten[:, targets_y1] > LearedThresholdFG\n",
    "        probflattens = probflattens.astype(float)\n",
    "        probr = probflatten.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probrs = probflattens.reshape((2, imgshape[0], imgshape[1], imgshape[2]))\n",
    "        probr_tensor = torch.tensor(probrs[np.newaxis, ...])\n",
    "        GTimgf = np.argmax(probr, axis = 0)\n",
    "        GT_tensor = torch.tensor(GTimgf[np.newaxis, ...])\n",
    "        softDSC = SoftDiceLoss(probr_tensor, GT_tensor)\n",
    "        softDSC_FG_CSATC.append(softDSC[1].numpy())\n",
    "\n",
    "        realDSC, _, _ = ComputMetric(GTimg, np.argmax(probr, axis = 0))\n",
    "        realDSC_FG.append(realDSC)\n",
    "        \n",
    "    softDSCs_AC.append(np.mean(np.array(softDSC_FG_AC)))\n",
    "    softDSCs_ATC.append(np.mean(np.array(softDSC_FG_ATC)))\n",
    "    softDSCs_CSATC.append(np.mean(np.array(softDSC_FG_CSATC)))\n",
    "    realDSCs.append(np.mean(np.array(realDSC_FG)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC_results:\n",
      "0.1049066211781956\n",
      "TS_ATC_results:\n",
      "0.1097389101742774\n",
      "CSTS_ATC_results:\n",
      "0.021114346746849644\n"
     ]
    }
   ],
   "source": [
    "print('AC_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_AC))))\n",
    "print('TS_ATC_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_ATC))))\n",
    "print('CSTS_ATC_results:')\n",
    "print(np.mean(np.abs(np.array(realDSCs) - np.array(softDSCs_CSATC))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modeleval",
   "language": "python",
   "name": "modeleval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
